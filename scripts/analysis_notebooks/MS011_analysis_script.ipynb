{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e036b291",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mne\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import seaborn as sns\n",
    "from scipy.stats import zscore, linregress, ttest_ind, ttest_rel, ttest_1samp\n",
    "import pandas as pd\n",
    "from mne.preprocessing.bads import _find_outliers\n",
    "from mne.filter import next_fast_len\n",
    "import os \n",
    "import joblib\n",
    "import emd\n",
    "import re\n",
    "import scipy\n",
    "import h5io\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "import re\n",
    "import difflib \n",
    "from mne.preprocessing.bads import _find_outliers\n",
    "from scipy.stats import kurtosis, zscore\n",
    "import neurodsp\n",
    "import mne\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from mne.filter import next_fast_len\n",
    "from scipy.signal import hilbert, find_peaks, peak_widths, convolve\n",
    "import Levenshtein as lev\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6f672a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/christinamaher/Documents/GitHub/LFPAnalysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58fabc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from LFPAnalysis import lfp_preprocess_utils, sync_utils, analysis_utils, nlx_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b7c2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'MS011'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb285da",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/Users/christinamaher/Desktop/fellowship_data' # this is the root directory for most un-archived data and results \n",
    "\n",
    "save_dir = f'{base_dir}/{subject}/Ephys'  # save intermediate results in the 'work' directory\n",
    "    \n",
    "# I have saved most of my raw data in the 'projects directory'\n",
    "behav_dir = f'{base_dir}/{subject}/Behavior'\n",
    "neural_dir = f'{base_dir}/{subject}/Ephys'\n",
    "anat_dir = f'{base_dir}/{subject}/Anat'\n",
    "edf_files = glob(f'{neural_dir}/*.edf')\n",
    "tfr_dir = save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd711447",
   "metadata": {},
   "outputs": [],
   "source": [
    "mne_data_reref = mne.io.read_raw_fif(f'{base_dir}/{subject}/Ephys/wm_ref_ieeg.fif', preload=True)\n",
    "photodiode = mne.io.read_raw_fif(f'{base_dir}/{subject}/Ephys/photodiode.fif', preload=True)\n",
    "\n",
    "\n",
    "#behavior data \n",
    "behav_df = pd.read_csv(f'{base_dir}/{subject}/Behavior/{subject}_clean.csv')\n",
    "beh_ts = behav_df['choice_ts'] #timestamp that should be aligned to photodiode \n",
    "\n",
    "# add column of ITI ts\n",
    "behav_df['iti_ts'] = behav_df['choice_ts'] + 1500\n",
    "\n",
    "#anat recon file\n",
    "anat_file = glob(f'{anat_dir}/{subject}_labels.csv')[0]\n",
    "elec_locs = pd.read_csv(anat_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14d2c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the photodiode and resample to match the neural data\n",
    "photodiode = mne.io.read_raw_fif(f'{base_dir}/{subject}/Ephys/photodiode.fif', preload=True)\n",
    "resample_sr = 500\n",
    "photodiode.resample(sfreq=resample_sr, npad='auto', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee5824c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load behavior data and save timestamp(s) of interest as variable \n",
    "behavior = pd.read_csv(f'{base_dir}/{subject}/Behavior/{subject}_clean.csv')\n",
    "choice_ts = np.array(behavior['choice_ts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d92cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot photodiode and choice timestamps before alignment\n",
    "%matplotlib qt\n",
    "plt.plot(photodiode._data[0])\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"V\")\n",
    "plt.title(\"Photodiode\")\n",
    "\n",
    "zeros = np.array([0.05] * len(choice_ts))\n",
    "x_ts = choice_ts\n",
    "y_ts = zeros.T\n",
    "plt.scatter(x_ts,y_ts,color='red')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7842c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample time-frequency data as an example\n",
    "time_frequency_data = photodiode._data[0]\n",
    "\n",
    "# Define the threshold values\n",
    "threshold_min = -0.15\n",
    "\n",
    "photodiode_deflected = []\n",
    "\n",
    "# Detect sequential peaks\n",
    "for value in time_frequency_data:\n",
    "    if value > threshold_min:\n",
    "        photodiode_deflected.append(1)\n",
    "    elif value < threshold_min:\n",
    "        photodiode_deflected.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838f70aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_sequential_values(arr):\n",
    "    if not arr:\n",
    "        return []\n",
    "\n",
    "    result = []\n",
    "    current_sum = arr[0]\n",
    "\n",
    "    for i in range(1, len(arr)):\n",
    "        if arr[i] == arr[i - 1]:\n",
    "            current_sum += arr[i]\n",
    "        else:\n",
    "            result.append(current_sum)\n",
    "            current_sum = arr[i]\n",
    "\n",
    "    # Append the last calculated sum\n",
    "    result.append(current_sum)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f180be",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = sum_sequential_values(photodiode_deflected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5d7e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_peak_indices(lengths):\n",
    "    photodiode_indices = []\n",
    "    \n",
    "    for l in lengths:\n",
    "        if l < 0:\n",
    "            l_temp = l * -1 # flip sign\n",
    "            drop_numbers = np.ones(l_temp, dtype=int)\n",
    "            photodiode_indices.append(drop_numbers)\n",
    "        elif (l > 800) | (l < 700):\n",
    "            drop_numbers = np.ones(l, dtype=int)\n",
    "            photodiode_indices.append(drop_numbers)\n",
    "        elif (1 < 800) & (l > 700): \n",
    "            keep_numbers = np.zeros(l, dtype=int)\n",
    "            photodiode_indices.append(keep_numbers)\n",
    "        else:\n",
    "            print(\"error\")\n",
    "    \n",
    "    return np.concatenate(photodiode_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9de6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "photodiode_indices = assign_peak_indices(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c829897b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_diode = photodiode._data[0].copy()\n",
    "peaks_to_exclude = [index for index, value in enumerate(photodiode_indices) if value == 1]\n",
    "new_diode[peaks_to_exclude] = np.min(photodiode._data[0]) # make these all super small\n",
    "\n",
    "photodiode_final = photodiode.copy()\n",
    "photodiode_final._data[0] = new_diode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337e0f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot photodiode\n",
    "plt.plot(photodiode_final._data[0])\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"V\")\n",
    "plt.title(\"Photodiode\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb448b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "slope, offset = sync_utils.synchronize_data(choice_ts, \n",
    "                                            photodiode_final, \n",
    "                                            smoothSize=11, windSize=10, height=0.7)\n",
    "print(slope,offset) # should be close to 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3f7e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "choice_ts = choice_ts * slope + offset\n",
    "\n",
    "%matplotlib qt\n",
    "plt.plot(photodiode_final._data[0])\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"V\")\n",
    "plt.title(\"Photodiode\")\n",
    "\n",
    "zeros = np.array([-0.15] * len(choice_ts))\n",
    "x_ts = choice_ts * 500\n",
    "y_ts = zeros.T\n",
    "plt.scatter(x_ts,y_ts,color='red')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f903f21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with your event name (matching your dataframe), and the time-window for the event\n",
    "evs = {'choice_ts': [-1.5, 1.5], # 1.5 seconds before choice, to 1.5 seconds after (full reward presentation)\n",
    "       'iti_ts': [0.0, 0.5]} # first half a second of ITI (due to the jitter, the ITI ranges from 0.5 to 1.5s)\n",
    "\n",
    "epochs_all_evs = {f'{x}': np.nan for x in evs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e2f892",
   "metadata": {},
   "outputs": [],
   "source": [
    "IED_args = {'peak_thresh':4,\n",
    "           'closeness_thresh':0.25, \n",
    "           'width_thresh':0.2}\n",
    "\n",
    "\n",
    "for event in evs.keys():\n",
    "    # Make the epochs. \n",
    "    ev_epochs = lfp_preprocess_utils.make_epochs(load_path=f'{neural_dir}/wm_ref_ieeg.fif', \n",
    "                 slope=slope, offset=offset,\n",
    "                 behav_name=event, behav_times=behav_df[event].values, \n",
    "                 ev_start_s=evs[event][0], ev_end_s=evs[event][1], buf_s = 1.0, IED_args=IED_args) #1.0 buf unsaved\n",
    "\n",
    "    epochs_all_evs[event] = ev_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0779750",
   "metadata": {},
   "outputs": [],
   "source": [
    "behav_params = ['r', 'acquired', 'condition','rd','ev','rpe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3691755c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in evs.keys():\n",
    "\n",
    "    event_metadata = epochs_all_evs[event].metadata.copy()\n",
    "    \n",
    "    #independent vars\n",
    "    for param in behav_params: \n",
    "        event_metadata[param] = behav_df[param].tolist()\n",
    "\n",
    "    epochs_all_evs[event].metadata = event_metadata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3ae6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_all_evs[event].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70626687",
   "metadata": {},
   "source": [
    "Save raw epoched data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05deb7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in evs.keys():\n",
    "    epochs_all_evs[event].save(f'{neural_dir}/epoch_{event}.fif', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3756b96",
   "metadata": {},
   "source": [
    "Baselining "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d30665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some spectrogram parameters \n",
    "freqs = np.logspace(*np.log10([2, 200]), num=30)\n",
    "n_cycles = 3\n",
    "sr = 500.0 \n",
    "buf = 1.0\n",
    "buf_ix = int(buf*sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997d1c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicitly define a list of analysis events and the baseline event. Should correspond to the dict\n",
    "analysis_evs = ['choice_ts']\n",
    "baseline_ev = ['iti_ts']\n",
    "evs = {'choice_ts': [-1.5, 1.5], # 1.5 seconds before choice, to 1.5 seconds after (full reward presentation)\n",
    "       'iti_ts': [0.0, 0.5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3869e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_all_baseline = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b56cfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#baseline epoch - \n",
    "event = 'iti_ts'\n",
    "epochs = epochs_all_evs[event]\n",
    "\n",
    "good_chans = [x for x in epochs.ch_names if x not in epochs.info['bads']]\n",
    "picks = [x for x in good_chans]\n",
    "\n",
    "pow_struct = np.nan * np.ones([epochs._data.shape[0], \n",
    "                       epochs._data.shape[1], len(freqs), \n",
    "                       epochs._data.shape[-1]])\n",
    "\n",
    "for ch_ix in np.arange(epochs._data.shape[1]): \n",
    "    ch_data = epochs._data[:, ch_ix:ch_ix+1, :]\n",
    "    bad_epochs  = np.where(epochs.metadata[epochs.ch_names[ch_ix]].notnull())[0] # this is where detected IEDs are removed.\n",
    "    good_epochs = np.delete(np.arange(ch_data.shape[0]), bad_epochs)\n",
    "    ch_data = np.delete(ch_data, bad_epochs, axis=0)\n",
    "    ch_pow = mne.time_frequency.tfr_array_morlet(ch_data, sfreq=epochs.info['sfreq'], \n",
    "                                        freqs=freqs, n_cycles=n_cycles, zero_mean=False, \n",
    "                                        use_fft=True, output='power', n_jobs=1)\n",
    "\n",
    "    pow_struct[good_epochs, ch_ix, :, :] = ch_pow[:, 0, :, :]\n",
    "\n",
    "temp_pow = mne.time_frequency.EpochsTFR(epochs.info, pow_struct, \n",
    "                                        epochs.times, freqs)\n",
    "temp_pow.crop(tmin=evs[event][0], tmax=evs[event][1]) # this is where you crop the buffer! \n",
    "\n",
    "epochs_all_baseline[event] = temp_pow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f8fb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "power_epochs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914f22dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "event = 'choice_ts'\n",
    "\n",
    "epochs = epochs_all_evs[event]\n",
    "\n",
    "# Let's make sure we only do this for good channels\n",
    "good_chans = [x for x in epochs.ch_names if x not in epochs.info['bads']]\n",
    "picks = [x for x in good_chans]\n",
    "\n",
    "pow_struct = np.nan * np.ones([epochs._data.shape[0], \n",
    "                       epochs._data.shape[1], len(freqs), \n",
    "                       epochs._data.shape[-1]])\n",
    "\n",
    "for ch_ix in np.arange(epochs._data.shape[1]): \n",
    "    ch_data = epochs._data[:, ch_ix:ch_ix+1, :]\n",
    "    bad_epochs  = np.where(epochs.metadata[epochs.ch_names[ch_ix]].notnull())[0] \n",
    "    good_epochs = np.delete(np.arange(ch_data.shape[0]), bad_epochs)\n",
    "    ch_data = np.delete(ch_data, bad_epochs, axis=0) #this is where bad epochs for ch are deleted!!\n",
    "    ch_pow = mne.time_frequency.tfr_array_morlet(ch_data, sfreq=epochs.info['sfreq'], \n",
    "                                        freqs=freqs, n_cycles=n_cycles, zero_mean=False, \n",
    "                                        use_fft=True, output='power', n_jobs=1)\n",
    "\n",
    "    pow_struct[good_epochs, ch_ix, :, :] = ch_pow[:, 0, :, :]\n",
    "\n",
    "temp_pow = mne.time_frequency.EpochsTFR(epochs.info, pow_struct, \n",
    "                                        epochs.times, freqs)\n",
    "\n",
    "temp_pow.crop(tmin=evs[event][0], tmax=evs[event][1]) # this is where you crop the buffer! \n",
    "\n",
    "\n",
    "baseline_corrected_power = lfp_preprocess_utils.baseline_trialwise_TFR(data=temp_pow.data, \n",
    "                                                  baseline_mne=epochs_all_baseline['iti_ts'], \n",
    "                                                  mode='zscore', \n",
    "                                                  trialwise=False, \n",
    "                                                  baseline_only=True)\n",
    "\n",
    "\n",
    "zpow = mne.time_frequency.EpochsTFR(epochs.info, baseline_corrected_power, \n",
    "                                temp_pow.times, freqs)\n",
    "\n",
    "zpow.metadata = epochs_all_evs[event].metadata\n",
    "\n",
    "power_epochs[event] = zpow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a89ac6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "power_epochs['choice_ts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3012e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "power_epochs['choice_ts'].save(f'{neural_dir}/wm_pow_epochs_final-tfr.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d4ec8e",
   "metadata": {},
   "source": [
    "Wavelet TFRs - all trials, every electrode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82afe1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "event = 'choice_ts'\n",
    "yticks = [4, 12, 30, 60, 90, 120, 150, 180, 200]\n",
    "good_ch = [x for x in power_epochs[event].ch_names if '-' in x]\n",
    "\n",
    "\n",
    "for ch in good_ch:\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "    times = power_epochs[event].times\n",
    "    plot_data = np.nanmean(np.nanmean(power_epochs[event].copy().pick_channels([ch]).data, axis=0), axis=0)\n",
    "\n",
    "    im = ax.imshow(plot_data,\n",
    "            extent=[times[0], times[-1], freqs[0], freqs[-1]], interpolation='Bicubic',\n",
    "            aspect='auto', origin='lower', cmap='RdBu_r',vmin = -np.nanmax(np.abs(plot_data)), vmax = np.nanmax(np.abs(plot_data)))\n",
    "    ax.set(yticks=yticks, xlabel='Time (s)', ylabel='Frequency',title=f'{ch} Encoding')\n",
    "    ax.yaxis.set_tick_params(labelsize=8)\n",
    "    fig.colorbar(im, ax=ax)\n",
    "    plt.savefig(f'{save_dir}/{ch}.png', format='png', metadata=None,\n",
    "    bbox_inches=None, pad_inches=0.1,\n",
    "    facecolor='auto', edgecolor='auto',\n",
    "    backend=None)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b057f0",
   "metadata": {},
   "source": [
    "Wavelet TFRs - REGION AVERAGED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df90ccb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "anat = pd.read_csv(f'{base_dir}/{subject}/Anat/{subject}_labels.csv')\n",
    "anat['bin'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd4c9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "anode_list = [x.split('-')[0] for x in epochs_all_evs['choice_ts'].ch_names]\n",
    "elec_df = anat[anat.NMMlabel.str.lower().isin(anode_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9fd0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = 'ofc'\n",
    "# band definitions for y-axis\n",
    "yticks = [4, 8, 13, 30, 60, 120]\n",
    "\n",
    "elecs_to_pick = elec_df.loc[elec_df['bin'] == region, 'NMMlabel'].str.lower() + '-'\n",
    "elecs_to_pick = elecs_to_pick.tolist()\n",
    "\n",
    "picks = []\n",
    "for e in elecs_to_pick:\n",
    "    picks_temp = list(filter(lambda s: e in s,  power_epochs['choice_ts'].info['ch_names']))[0]\n",
    "    picks.append(picks_temp)\n",
    "\n",
    "num_elecs = len(picks)\n",
    "    \n",
    "for event in analysis_evs:\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "    times = power_epochs[event].times\n",
    "    plot_data = np.nanmean(np.nanmean(power_epochs[event].copy().pick_channels(picks).data, axis=0), axis=0)\n",
    "\n",
    "    im = ax.imshow(plot_data,extent=[times[0], times[-1], freqs[0], freqs[-1]], interpolation='Bicubic',aspect='auto', origin='lower', cmap='RdBu_r', vmin = -np.nanmax(np.abs(plot_data)), vmax = np.nanmax(np.abs(plot_data)))\n",
    "    ax.set(yticks=yticks, xlabel='Time (s)', ylabel='Frequency', title = f'{region} - {num_elecs} electrodes')\n",
    "    fig.colorbar(im, ax=ax)\n",
    "    plt.savefig(f'{save_dir}/{region}.png', format='png', metadata=None,\n",
    "    bbox_inches=None, pad_inches=0.1,\n",
    "    facecolor='auto', edgecolor='auto',\n",
    "    backend=None)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c76d4f",
   "metadata": {},
   "source": [
    "With contrasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57346d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = 'hippocampus'\n",
    "# band definitions for y-axis\n",
    "yticks = [4, 8, 13, 30, 60, 120]\n",
    "\n",
    "conditions = [\"(condition == 'hint')\",\n",
    "             \"(condition == 'no_hint')\"]\n",
    "\n",
    "cond_name = 'Context'\n",
    "\n",
    "elecs_to_pick = elec_df.loc[elec_df['bin'] == region, 'NMMlabel'].str.lower() + '-'\n",
    "elecs_to_pick = elecs_to_pick.tolist()\n",
    "\n",
    "picks = []\n",
    "for e in elecs_to_pick:\n",
    "    picks_temp = list(filter(lambda s: e in s,  power_epochs['choice_ts'].info['ch_names']))[0]\n",
    "    picks.append(picks_temp)\n",
    "\n",
    "    \n",
    "for event in analysis_evs:\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 6), dpi=300)\n",
    "    for ix, cond in enumerate(conditions):\n",
    "        times = power_epochs[event].times\n",
    "        plot_data = np.nanmean(np.nanmean(power_epochs[event][cond].copy().pick_channels(picks).data, axis=0), axis=0)\n",
    "\n",
    "        im = ax[ix].imshow(plot_data,\n",
    "                    extent=[times[0], times[-1], freqs[0], freqs[-1]], interpolation='Bicubic',\n",
    "                    aspect='auto', origin='lower', cmap='RdBu_r', vmin = -np.nanmax(np.abs(plot_data)), vmax = np.nanmax(np.abs(plot_data)))\n",
    "        ax[ix].set(yticks=yticks, xlabel='Time (s)', ylabel='Frequency', title=f'{region}_{cond}')\n",
    "        fig.colorbar(im, ax=ax[ix])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2624b72b",
   "metadata": {},
   "source": [
    "Save data for regressions and determine encoding elecs using permutation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "260d1e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = \"MS011\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c84d02a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load power epochs and subset instructed trials\n",
    "power_epochs = mne.time_frequency.read_tfrs(f'/Users/christinamaher/Desktop/fellowship_data/{subject}/Ephys/wm_pow_epochs_final-tfr.h5')\n",
    "data = power_epochs[0].to_data_frame()\n",
    "hfa_df = data.loc[data['freq'] >= 60]\n",
    "hfa_df_melt = pd.melt(hfa_df, id_vars=[\"time\", \"freq\",\"epoch\",\"condition\"],var_name=\"electrode\", value_name=\"power\")\n",
    "average_by_epoch = hfa_df_melt.groupby(['time','epoch','electrode'])['power'].mean()\n",
    "average_by_epoch.to_csv(f'/Users/christinamaher/Desktop/fellowship_data/{subject}/Ephys/average_by_epoch.csv')\n",
    "regressors = power_epochs[0].metadata\n",
    "regressors.to_csv(f'/Users/christinamaher/Desktop/fellowship_data/{subject}/Ephys/regressors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fff10bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation_df = pd.read_csv(f'/Users/christinamaher/Desktop/fellowship_data/{subject}/Ephys/average_by_epoch.csv')\n",
    "electrode_list = permutation_df[permutation_df['electrode'].str.contains('-')]['electrode'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee69b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_null_permutation(timeseries=None, win_len=200, slide_len=50):\n",
    "    # Generate permuted timeseries\n",
    "    surr = np.zeros((timeseries.shape))\n",
    "    \n",
    "    shuffles = np.random.randint(1, 300) # 3rd dimension of epoched data is timestamps\n",
    "    surr_ts = np.roll(timeseries, shuffles, axis=1)\n",
    "    np.random.shuffle(surr_ts)\n",
    "    \n",
    "    #surr = np.concatenate(surr_list)\n",
    "    return surr_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943712e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_elec = []\n",
    "electrode_name = []\n",
    "for e in electrode_list:\n",
    "    #electrode_data = power_epochs[0].copy().pick_channels([e]).data\n",
    "    electrode_data = np.nanmean(np.nanmean(power_epochs[0].copy().pick_channels([e]).data, axis=0), axis=0)\n",
    "    null_permutation = get_null_permutation(timeseries=electrode_data)\n",
    "    F_obs, clusters, cluster_p_values, H0 = mne.stats.permutation_cluster_test([electrode_data, null_permutation], out_type='mask', tail=0)\n",
    "    \n",
    "    # Create a boolean mask for values lower than 0.05\n",
    "    mask = cluster_p_values < 0.001\n",
    "    contains_value_lower_than_0_01 = np.any(mask)\n",
    "\n",
    "    # Print the result\n",
    "    if contains_value_lower_than_0_01:\n",
    "        encoding = 1\n",
    "    else:\n",
    "        encoding = 0 \n",
    "        \n",
    "    encoding_elec.append(encoding) # save data so that encoding versus non-encoding electrodes can be subset\n",
    "    electrode_name.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a676f0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip the arrays together\n",
    "zipped_data = list(zip(electrode_name, encoding_elec))\n",
    "\n",
    "# Create a DataFrame\n",
    "encoding_df = pd.DataFrame(zipped_data, columns=['name', 'encoding'])\n",
    "\n",
    "encoding_df.to_csv(f'/Users/christinamaher/Desktop/fellowship_data/{subject}/Ephys/encoding_electrodes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6e7bf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "power_epochs = mne.time_frequency.read_tfrs(fname='/Users/christinamaher/Desktop/fellowship_data/MS011/Ephys/wm_pow_epochs_final-tfr.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcfa2f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['rmolf3-rmolf4', 'rmolf5-rmolf7']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region = 'ofc'\n",
    "\n",
    "elec_df = pd.read_csv('/Users/christinamaher/Desktop/fellowship_data/MS011/Anat/MS011_labels.csv')\n",
    "\n",
    "elecs_to_pick = elec_df.loc[elec_df['bin'] == region, 'label'].str.lower() + '-'\n",
    "elecs_to_pick = elecs_to_pick.tolist()\n",
    "\n",
    "picks = []\n",
    "for e in elecs_to_pick:\n",
    "    picks_temp = list(filter(lambda s: e in s,  power_epochs[0].info['ch_names']))\n",
    "    picks.append(picks_temp)\n",
    "\n",
    "picks = [item for sublist in picks for item in sublist]\n",
    "picks = [picks]\n",
    "picks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aceae4dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "164dd7236ad446788a3671be537bd1d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Permuting : 0/499 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "subj_id = 'MS011'\n",
    "region = 'ofc'\n",
    "analysis_evs = ['choice_ts']\n",
    "freqs = np.logspace(*np.log10([2, 200]), num=30)\n",
    "yticks = [4, 13, 30, 60, 120]\n",
    "\n",
    "\n",
    "\n",
    "save_path = '/Users/christinamaher/Desktop/christinamaher/fellowship_data/MS011/Ephys'\n",
    "# Get electrode df \n",
    "\n",
    "elec_df = pd.read_csv('/Users/christinamaher/Desktop/fellowship_data/MS011/Anat/MS011_labels.csv')\n",
    "\n",
    "elecs_to_pick = elec_df.loc[elec_df['bin'] == region, 'label'].str.lower() + '-'\n",
    "elecs_to_pick = elecs_to_pick.tolist()\n",
    "\n",
    "picks = []\n",
    "for e in elecs_to_pick:\n",
    "    picks_temp = list(filter(lambda s: e in s,  power_epochs[0].info['ch_names']))\n",
    "    picks.append(picks_temp)\n",
    "\n",
    "picks = [item for sublist in picks for item in sublist][1]\n",
    "picks = [picks]\n",
    "    \n",
    "conditions = [\"(condition == 'no_hint')\",\n",
    "             \"(condition == 'hint')\"]\n",
    "\n",
    "cond_name = 'Context'\n",
    "\n",
    "\n",
    "for event in analysis_evs:\n",
    "    \n",
    "    # Average the data in each condition across channels \n",
    "    X = [np.nanmean(power_epochs[0][conditions[0]].copy().pick_channels(picks).data, axis=1), \n",
    "         np.nanmean(power_epochs[0][conditions[1]].copy().pick_channels(picks).data, axis=1)]\n",
    "    \n",
    "    F_obs, clusters, cluster_p_values, H0 = \\\n",
    "    mne.stats.permutation_cluster_test(X, n_permutations=500, out_type='mask', verbose=True)\n",
    "    \n",
    "    if any(cluster_p_values<=0.05):\n",
    "        # Create new stats image with only significant clusters\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(6, 4), dpi=300)\n",
    "\n",
    "        times =  power_epochs[0][conditions[0]].times\n",
    "\n",
    "\n",
    "        # Average the data in each condition across epochs for plotting\n",
    "        evoked_power_1 = np.nanmean(X[0], axis=0)\n",
    "        evoked_power_2 = np.nanmean(X[1], axis=0)\n",
    "        evoked_power_contrast = evoked_power_1 - evoked_power_2\n",
    "        signs = np.sign(evoked_power_contrast)\n",
    "\n",
    "        F_obs_plot = np.nan * np.ones_like(F_obs)\n",
    "        for c, p_val in zip(clusters, cluster_p_values):\n",
    "            if p_val <= 0.05:\n",
    "                F_obs_plot[c] = F_obs[c] * signs[c]\n",
    "\n",
    "        ax.imshow(F_obs,\n",
    "                  extent=[times[0], times[-1], freqs[0], freqs[-1]], interpolation = 'Bicubic',\n",
    "                  aspect='auto', origin='lower', cmap='gray')\n",
    "        max_F = np.nanmax(abs(F_obs_plot))\n",
    "        ax.imshow(F_obs_plot,\n",
    "                  extent=[times[0], times[-1], freqs[0], freqs[-1]],\n",
    "                  aspect='auto', origin='lower', cmap='RdBu_r',\n",
    "                  vmin=-max_F, vmax=max_F)\n",
    "\n",
    "        ax.set(yticks=yticks, xlabel='Time (s)', ylabel='Frequency', title=f'{subj_id}_{region}_{cond_name}_{event}')\n",
    "        \n",
    "        # # ax.set_title(f'Induced power ({ch_name})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d02feb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
