{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MS002 Preprocess\n",
    "01/10/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mne\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import seaborn as sns\n",
    "from scipy.stats import zscore, linregress, ttest_ind, ttest_rel, ttest_1samp\n",
    "import pandas as pd\n",
    "from mne.preprocessing.bads import _find_outliers\n",
    "import os \n",
    "import joblib\n",
    "import emd\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/alexandrafink/Documents/GitHub/afink_lfp_pipeline/LFPAnalysis/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LFPAnalysis import lfp_preprocess_utils, sync_utils, analysis_utils, nlx_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify root directory for un-archived data and results \n",
    "base_dir = '/Users/alexandrafink/Documents/GraduateSchool/SaezLab/SWB/'\n",
    "anat_dir = f'{base_dir}anat_recons/recon_labels/'\n",
    "neural_dir = f'{base_dir}ephys_analysis/data/'\n",
    "behav_dir = f'{base_dir}behavior_analysis/behavior_preprocessed/'\n",
    "\n",
    "subj_id = 'MS002'\n",
    "subj_format = ['edf']\n",
    "subj_site = ['MSSM']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make mne_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and resample data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_files = glob(f'{neural_dir}{subj_id}/raw/*.edf')\n",
    "\n",
    "mne_data = mne.io.read_raw_edf(edf_files[0], preload=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne_data.ch_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check one channel data\n",
    "plt.plot(mne_data._data[0,:4999])\n",
    "plt.title(\"Raw iEEG, electrode 0, samples 0-4999\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#resampling if patient is not sampled at 512\n",
    "resample_sr = 500\n",
    "mne_data.resample(sfreq=resample_sr, npad='auto', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Photodiode\n",
    "- examine photodiode \n",
    "- save out before resampling/notch filtering *unless nlx - then you have to resample first "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check the photodiode\n",
    "trig_ix = mne_data.ch_names.index(\"DC1\")\n",
    "plt.plot(mne_data._data[trig_ix])\n",
    "plt.title(\"Photodiode\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne_data.save(f'{neural_dir}{subj_id}/photodiode.fif', picks='DC1', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne_data.drop_channels(['DC1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notch filter line noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne_data.info['line_freq'] = 60\n",
    "# Notch out 60 Hz noise and harmonics \n",
    "mne_data.notch_filter(freqs=(60, 120, 180, 240))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anatomical Localization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Rename channels to be lowercase before anatomical localization\n",
    "new_name_dict = {x:x.replace(\" \", \"\").lower() for x in mne_data.ch_names}\n",
    "mne_data.rename_channels(new_name_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the electrode localization data\n",
    "anat_file = glob(f'{anat_dir}{subj_id}_labels.csv')[0]\n",
    "elec_locs = pd.read_csv(anat_file)\n",
    "# Sometimes there's extra columns with no entries: \n",
    "elec_locs = elec_locs[elec_locs.columns.drop(list(elec_locs.filter(regex='Unnamed')))]\n",
    "\n",
    "elec_locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(elec_locs.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anat_names = list(elec_locs.label.str.lower())\n",
    "sum([ch not in mne_data.ch_names for ch in anat_names]) #if there are no missing channels, sum = 0. if sum >0, find the missing elecs\n",
    "print([ch for ch in mne_data.ch_names if ch not in anat_names ]) #print extra channels in mne_data.ch_names and make sure none of them are neural channels (will be EEG etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mne_names, unmatched_names, unmatched_seeg = lfp_preprocess_utils.match_elec_names(mne_data.ch_names, elec_locs.label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unmatched_seeg #make sure there are no unmatched names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_name_dict = {x:y for (x,y) in zip(mne_data.ch_names, new_mne_names)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_name_dict #make sure this passes the eye test \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the mne data according to the localization data\n",
    "\n",
    "mne_data.rename_channels(new_name_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_seeg_names = [i for i in mne_data.ch_names if i.startswith('r')]\n",
    "left_seeg_names = [i for i in mne_data.ch_names if i.startswith('l')]\n",
    "print(f'We have a total of {len(left_seeg_names)} left sEEG and {len(right_seeg_names)} right sEEG electrodes')\n",
    "print(f'We have a total of {len(left_seeg_names) + len(right_seeg_names)} sEEG electrodes')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sEEG_mapping_dict = {f'{x}':'seeg' for x in left_seeg_names+right_seeg_names}\n",
    "mne_data.set_channel_types(sEEG_mapping_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_chans = list(set(mne_data.ch_names)^set(left_seeg_names+right_seeg_names))\n",
    "mne_data.drop_channels(drop_chans) #number of chans should = number of seegs + 1 (photodiode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make montage (convert mm to m)\n",
    "\n",
    "montage = mne.channels.make_dig_montage(ch_pos=dict(zip(elec_locs.label, \n",
    "                                                        elec_locs[['mni_x', 'mni_y', 'mni_z']].to_numpy(dtype=float)/1000)),\n",
    "                                        coord_frame='mni_tal')\n",
    "\n",
    "mne_data.set_montage(montage, match_case=False, on_missing='warn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signal Cleaning \n",
    "Methods:\n",
    "- Remove all channels that are obviously noise\n",
    "- Be LIBERAL with bad labeling - these channels are NOT removed from the dataset, they are just NOT USED to rereference other channels. \n",
    "- This process is iterative depending on how TFRs look. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is just for my own personal info and to select how many channels to visualize at a time\n",
    "ch_names = list(elec_locs.label.str.lower())\n",
    "pattern = '[0-9]'\n",
    "ch_names_no_num = [re.sub(pattern, '', i) for i in ch_names]\n",
    "probe_names = np.unique(ch_names_no_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe_ch_counts = {} #need this to select channel number for visualization\n",
    "for p in probe_names:\n",
    "    c = ch_names_no_num.count(p)\n",
    "    probe_ch_counts[p] = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe_ch_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfp_preprocess_utils.detect_bad_elecs(mne_data, sEEG_mapping_dict) #this is likely inaccurate - just use to get an idea "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook \n",
    "fig = mne_data.plot(start=0, duration=500, n_channels=20, scalings=mne_data._data.max()/20)\n",
    "fig.fake_keypress('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne_data.info['bads']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#add manually for situations where raw data needs to be updated but manual bad channel inspection does not change \n",
    "\n",
    "mne_data.info['bads'] = ['lmoif1', 'lmoif2','rmoif9', 'lmoif12', 'lmoif13', 'rmoif1','rmoif2','rmoif3',\n",
    "                         'rmoif4','rmoif5','lacas10','lacas9','lacas8','lacas1','lacas6','racas1','racas2','racas12',\n",
    "                         'laims1','laims2','laims3','laims5','raims2','raims3','raims4','raims5','raims1','raims14',\n",
    "                         'lsif7','lsif4','lsif5','raims11','raims12','raims10','lpips12','lpips11','lagit1','lagit2',\n",
    "                         'lagit8','lagit9', 'ragit1', 'ragit6', 'lagit10', 'lagit7', 'lhplt2', 'lhplt3', \n",
    "                         'ragit9', 'lhplt1', 'lhplt10', 'lhplt9', 'lhplt8','lhplt6', 'lhplt7', 'rhplt11',\n",
    "                         'lhplt11', 'lhplt12', 'rhplt1', 'rhplt2', 'rhplt3', 'rhplt5', 'rhplt8', 'rhplt9',\n",
    "                         'rhplt10', 'rhplt12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mne_data.info #sanity check that bads info saved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-referencing \n",
    "- wm reref\n",
    "- bipolar reref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run if only re-ref\n",
    "anat_file = glob(f'{anat_dir}/{subj_id}_labels.csv')[0]\n",
    "# mne_data = mne.io.read_raw_fif(f'{neural_dir}{subj_id}/raw_ieeg.fif', preload=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WM Re-ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-reference neural data\n",
    "mne_data_wm_reref = lfp_preprocess_utils.ref_mne(mne_data=mne_data, \n",
    "                                              elec_path=anat_file, \n",
    "                                              method='wm', \n",
    "                                              site='MSSM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne_data_wm_reref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne_data_wm_reref.ch_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne_data_wm_reref.save(f'{neural_dir}{subj_id}/wm_ref_ieeg.fif',overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bipolar Re-ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-reference neural data\n",
    "mne_data_bp_reref = lfp_preprocess_utils.ref_mne(mne_data=mne_data, \n",
    "                                              elec_path=anat_file, \n",
    "                                              method='bipolar', \n",
    "                                              site='MSSM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne_data_bp_reref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne_data_bp_reref.ch_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne_data_bp_reref.save(f'{neural_dir}{subj_id}/bp_ref_ieeg.fif',overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save mne_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne_data.save(f'{neural_dir}{subj_id}/raw_ieeg.fif',overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epoching + TFRs\n",
    "- Check whether data is ready to be analyzed - if this step shows noise then steps above should be repeated\n",
    "- Align photodiode to behavior \n",
    "- Epoch data (and mark bad epochs)\n",
    "- Baseline data\n",
    "- Visualize TFRs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove mne_data from environment to save memory \n",
    "del mne_data, mne_data_bp_reref, mne_data_wm_reref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Photodiode Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load behavior data\n",
    "behav_dir = '/Users/alexandrafink/Documents/GraduateSchool/SaezLab/SWB/behavior_analysis/behavior_preprocessed/'\n",
    "behav_df = pd.read_csv(f'{behav_dir}{subj_id}_task_data')\n",
    "behav_df = behav_df[behav_df.columns.drop(list(behav_df.filter(regex='Unnamed')))]\n",
    "behav_df = behav_df[behav_df['FeedbackOnset'] != 0] #remove fail trials from behav df\n",
    "beh_ts = behav_df['TrialOnset'] #timestamp that should be aligned to photodiode \n",
    "#load photodiode data\n",
    "photodiode_data = mne.io.read_raw_fif(f'{neural_dir}{subj_id}/photodiode.fif', preload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Photodiode alignment\n",
    "\n",
    "# Synchronize to the photodiode or whatever your neural sync signal is\n",
    "slope, offset = sync_utils.synchronize_data(beh_ts, \n",
    "                                            photodiode_data, \n",
    "                                            smoothSize=11, windSize=15, height=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(slope, offset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epoch Data\n",
    "- Epoch neural data into trial epochs \n",
    "- Add behavioral data to epochs metadata\n",
    "- Save epochs\n",
    "- Baseline + decompose data into TFRs\n",
    "- Plot + save TFRs (examine quality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epoch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IED removal requires that we set some parameters for IED detection. \n",
    "# 1. peak_thresh: how many stds should they exceed the baseline by? \n",
    "# 2. closeness_thresh: how close should they be allowed to be (in sec) to other candidate IEDs? \n",
    "# 3. width_thresh: how wide should they have to be (in sec)?\n",
    "\n",
    "# Defaults:\n",
    "IED_args = {'peak_thresh':4,\n",
    "           'closeness_thresh':0.25, \n",
    "           'width_thresh':0.2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with your event name (matching your dataframe), and the time-window for the event\n",
    "evs = {'TrialOnset': [-1.0, 0], #ITI is always at least one second + 10ms buffer for wavelet padding (no horizontal smearing)\n",
    "       'DecisionOnset': [0, 5.0]} #1 sec decision period + 2 second outcome + 3 second counterfactual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_all_evs = {f'{x}': np.nan for x in evs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MAKE SURE CORRECT REREF FILE IS BEING USED!\n",
    "for event in evs.keys():\n",
    "    # Make the epochs. \n",
    "    ev_epochs = lfp_preprocess_utils.make_epochs(load_path=f'{neural_dir}{subj_id}/wm_ref_ieeg.fif', \n",
    "#     ev_epochs = lfp_preprocess_utils.make_epochs(load_path=f'{neural_dir}{subj_id}/bp_ref_ieeg.fif', \n",
    "                 slope=slope, offset=offset,\n",
    "                 behav_name=event, behav_times=behav_df[event].values, \n",
    "                 ev_start_s=evs[event][0], ev_end_s=evs[event][1], buf_s = 1.0, IED_args=IED_args) #1.0 buf unsaved\n",
    "\n",
    "    epochs_all_evs[event] = ev_epochs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_all_evs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add behavioral data to metadata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behav_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behav_params = ['SafeBet', 'LowBet', 'HighBet','GambleChoice', 'Outcome',\n",
    "                'Profit', 'TotalProfit', 'GambleEV', 'CR', 'choiceEV', 'RPE',\n",
    "                'totalCPE', 'decisionCPE', 'totalRegret', 'decisionRegret',\n",
    "                'totalRelief', 'decisionRelief', 'totalCF', 'decisionCF', 'pRPE','nRPE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in evs.keys():\n",
    "\n",
    "    event_metadata = epochs_all_evs[event].metadata.copy()\n",
    "    \n",
    "    #independent vars\n",
    "    for param in behav_params: \n",
    "        event_metadata[param] = behav_df[param].tolist()\n",
    "\n",
    "    epochs_all_evs[event].metadata = event_metadata \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_all_evs[event].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save raw epoched data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in evs.keys():\n",
    "    epochs_all_evs[event].save(f'{neural_dir}{subj_id}/wm_epoch_{event}.fif', overwrite=True)\n",
    "#     epochs_all_evs[event].save(f'{neural_dir}{subj_id}/bp_epoch_{event}.fif', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline + Decompose into TFRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicitly define a list of analysis events and the baseline event. Should correspond to the dict\n",
    "analysis_evs = ['DecisionOnset']\n",
    "baseline_ev = 'TrialOnset'\n",
    "evs = {'TrialOnset': [-1.0, 0], #maybe increase to full second to take cycles up to 4\n",
    "       #ITI is always at least one second + 10ms buffer for wavelet padding (no horizontal smearing)\n",
    "       'DecisionOnset': [0, 5.0]} #1 sec decision period + 2 second outcome + 3 second counterfactual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some spectrogram parameters \n",
    "freqs = np.logspace(*np.log10([2, 200]), num=30)\n",
    "n_cycles = 3\n",
    "sr = 500.0 \n",
    "buf = 1.0\n",
    "buf_ix = int(buf*sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_all_baseline = {} #removed unecessary 'decisiononset' empty key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#baseline epoch - \n",
    "event = 'TrialOnset'\n",
    "epochs = epochs_all_evs[event]\n",
    "\n",
    "good_chans = [x for x in epochs.ch_names if x not in epochs.info['bads']]\n",
    "picks = [x for x in good_chans]\n",
    "\n",
    "pow_struct = np.nan * np.ones([epochs._data.shape[0], \n",
    "                       epochs._data.shape[1], len(freqs), \n",
    "                       epochs._data.shape[-1]])\n",
    "\n",
    "for ch_ix in np.arange(epochs._data.shape[1]): \n",
    "    ch_data = epochs._data[:, ch_ix:ch_ix+1, :]\n",
    "    bad_epochs  = np.where(epochs.metadata[epochs.ch_names[ch_ix]].notnull())[0]\n",
    "    good_epochs = np.delete(np.arange(ch_data.shape[0]), bad_epochs)\n",
    "    ch_data = np.delete(ch_data, bad_epochs, axis=0)\n",
    "    ch_pow = mne.time_frequency.tfr_array_morlet(ch_data, sfreq=epochs.info['sfreq'], \n",
    "                                        freqs=freqs, n_cycles=n_cycles, zero_mean=False, \n",
    "                                        use_fft=True, output='power', n_jobs=1)\n",
    "\n",
    "    pow_struct[good_epochs, ch_ix, :, :] = ch_pow[:, 0, :, :]\n",
    "\n",
    "temp_pow = mne.time_frequency.EpochsTFR(epochs.info, pow_struct, \n",
    "                                        epochs.times, freqs)\n",
    "temp_pow.crop(tmin=evs[event][0], tmax=evs[event][1])\n",
    "\n",
    "epochs_all_baseline[event] = temp_pow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_all_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_epochs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event = 'DecisionOnset'\n",
    "\n",
    "epochs = epochs_all_evs[event]\n",
    "\n",
    "# Let's make sure we only do this for good channels\n",
    "good_chans = [x for x in epochs.ch_names if x not in epochs.info['bads']]\n",
    "picks = [x for x in good_chans]\n",
    "\n",
    "pow_struct = np.nan * np.ones([epochs._data.shape[0], \n",
    "                       epochs._data.shape[1], len(freqs), \n",
    "                       epochs._data.shape[-1]])\n",
    "\n",
    "for ch_ix in np.arange(epochs._data.shape[1]): \n",
    "    ch_data = epochs._data[:, ch_ix:ch_ix+1, :]\n",
    "    bad_epochs  = np.where(epochs.metadata[epochs.ch_names[ch_ix]].notnull())[0] \n",
    "    good_epochs = np.delete(np.arange(ch_data.shape[0]), bad_epochs)\n",
    "    ch_data = np.delete(ch_data, bad_epochs, axis=0) #this is where bad epochs for ch are deleted!!\n",
    "    ch_pow = mne.time_frequency.tfr_array_morlet(ch_data, sfreq=epochs.info['sfreq'], \n",
    "                                        freqs=freqs, n_cycles=n_cycles, zero_mean=False, \n",
    "                                        use_fft=True, output='power', n_jobs=1)\n",
    "\n",
    "    pow_struct[good_epochs, ch_ix, :, :] = ch_pow[:, 0, :, :]\n",
    "\n",
    "temp_pow = mne.time_frequency.EpochsTFR(epochs.info, pow_struct, \n",
    "                                        epochs.times, freqs)\n",
    "\n",
    "temp_pow.crop(tmin=evs[event][0], tmax=evs[event][1])\n",
    "\n",
    "\n",
    "baseline_corrected_power = lfp_preprocess_utils.baseline_trialwise_TFR(data=temp_pow.data, \n",
    "                                                  baseline_mne=epochs_all_baseline['TrialOnset'], \n",
    "                                                  mode='zscore', \n",
    "                                                  trialwise=True, ## make sure this is true!\n",
    "                                                  baseline_only=False)\n",
    "\n",
    "\n",
    "zpow = mne.time_frequency.EpochsTFR(epochs.info, baseline_corrected_power, \n",
    "                                temp_pow.times, freqs)\n",
    "\n",
    "zpow.metadata = epochs_all_evs[event].metadata\n",
    "\n",
    "power_epochs[event] = zpow\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_epochs['DecisionOnset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install -c conda-forge h5io must install to save tfr data\n",
    "# power_epochs['DecisionOnset'].save(f'{neural_dir}{subj_id}/bp_pow_epochs-tfr.h5', overwrite=True)\n",
    "power_epochs['DecisionOnset'].save(f'{neural_dir}{subj_id}/wm_pow_epochs-tfr.h5', overwrite=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot TFRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####add directory for TFRs\n",
    "tfr_dir = f'{base_dir}ephys_analysis/figs/TFRs/{subj_id}/all_trials/'\n",
    "os.makedirs(tfr_dir,exist_ok = True) #added so you don't have to manually make subject folders in clean_data\n",
    "date = '01102024' #add date to file name --- update every run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event = 'DecisionOnset'\n",
    "yticks = [4, 12, 30, 60, 90, 120, 150, 180, 200]\n",
    "good_ch = [x for x in power_epochs[event].ch_names if '-' in x]\n",
    "save_path = tfr_dir\n",
    "\n",
    "\n",
    "\n",
    "for ch in good_ch:\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "    times = power_epochs[event].times\n",
    "    plot_data = np.nanmean(np.nanmean(power_epochs[event].copy().pick_channels([ch]).data, axis=0), axis=0)\n",
    "\n",
    "    im = ax.imshow(plot_data,\n",
    "            extent=[times[0], times[-1], freqs[0], freqs[-1]], interpolation='Bicubic',\n",
    "            aspect='auto', origin='lower', cmap='RdBu_r',vmin = -np.nanmax(np.abs(plot_data)), vmax = np.nanmax(np.abs(plot_data)))\n",
    "    ax.set(yticks=yticks, xlabel='Time (s)', ylabel='Frequency',title=f'{ch} Encoding')\n",
    "    ax.yaxis.set_tick_params(labelsize=8)\n",
    "    fig.colorbar(im, ax=ax)\n",
    "    plt.savefig(f'{save_path}/{ch}_{date}_wm_ref.png', format='png', metadata=None,\n",
    "#     plt.savefig(f'{save_path}/{ch}_{date}_bp_ref.png', format='png', metadata=None,\n",
    "    bbox_inches=None, pad_inches=0.1,\n",
    "    facecolor='auto', edgecolor='auto',\n",
    "    backend=None)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:swb_ephys]",
   "language": "python",
   "name": "conda-env-swb_ephys-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
