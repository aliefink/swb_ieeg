{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63c15ef6",
   "metadata": {},
   "source": [
    "# SWB CPE Connectivity Analysis: Theta Coherence\n",
    "\n",
    "Created: 10/07/2024 \\\n",
    "Updated: 11/20/2024 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82b06ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mne\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import seaborn as sns\n",
    "from scipy.stats import zscore, linregress, ttest_ind, ttest_rel, ttest_1samp, pearsonr, spearmanr\n",
    "import pandas as pd\n",
    "from mne.preprocessing.bads import _find_outliers\n",
    "import os \n",
    "import joblib\n",
    "import re\n",
    "import datetime\n",
    "import scipy\n",
    "import random\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.regression.mixed_linear_model import MixedLM \n",
    "from joblib import Parallel, delayed\n",
    "import pickle\n",
    "import itertools\n",
    "import time \n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "\n",
    "\n",
    "import mne_connectivity\n",
    "from mne_connectivity import phase_slope_index, seed_target_indices, spectral_connectivity_epochs\n",
    "# import fooof\n",
    "# Import plotting functions\n",
    "# from fooof.plts.spectra import plot_spectrum, plot_spectra\n",
    "# # Import the FOOOF object\n",
    "# from fooof import FOOOF\n",
    "# from fooof import FOOOFGroup\n",
    "\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from joblib import delayed, Parallel\n",
    "from statsmodels.stats import multitest\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# print('\\n'.join(f'{m.__name__}=={m.__version__}' for m in globals().values() if getattr(m, '__version__', None)))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d63e14b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "band = 'theta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e13b8c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11202024\n"
     ]
    }
   ],
   "source": [
    "# Specify root directory for un-archived data and results \n",
    "base_dir   = '/sc/arion/projects/guLab/Alie/SWB/'\n",
    "neural_dir = f'{base_dir}ephys_analysis/data/'\n",
    "behav_dir  = f'{base_dir}ephys_analysis/behav/behav_data/'\n",
    "save_dir   = f'{base_dir}ephys_analysis/results/connectivity/coherence/{band}/'\n",
    "os.makedirs(save_dir,exist_ok=True)\n",
    "\n",
    "script_dir = '/hpc/users/finka03/swb_ephys_analysis/scripts/'\n",
    "\n",
    "date = datetime.date.today().strftime('%m%d%Y')\n",
    "print(date)\n",
    "\n",
    "# anat_dir   = f'{base_dir}ephys_analysis/recon_labels/'\n",
    "# behav_dir  = f'{base_dir}swb_behav_models/data/behavior_preprocessed/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ebfd527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(f'{base_dir}ephys_analysis/LFPAnalysis/')\n",
    "\n",
    "from LFPAnalysis import oscillation_utils\n",
    "\n",
    "sys.path.append(f'{script_dir}analysis_notebooks/')\n",
    "\n",
    "from ieeg_tools import *\n",
    "\n",
    "sys.path.append(f'{script_dir}behav/')\n",
    "\n",
    "from behav_utils import *\n",
    "from swb_subj_behav import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9316f53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_ids = list(pd.read_excel(f'{base_dir}ephys_analysis/subj_info/SWB_subjects.xlsx', \n",
    "                              sheet_name='Usable_Subjects', usecols=[0]).PatientID)\n",
    "n_subj = len(subj_ids)\n",
    "# subj_ids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fb5f14-a38b-477e-8ebd-5f0b67a60f96",
   "metadata": {},
   "source": [
    "# Load Behav + Elec ROI Data\n",
    "- all_behav from updated task_dfs and behav_utils formatting\n",
    "- roi_reref_labels same as usual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30605ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # all_behav = pd.read_csv(f'{behav_dir}all_behav.csv') ## this isn't normalized yet \n",
    "# raw_behav = [pd.read_csv(f'{behav_dir}{subj_id}_task_df.csv') for subj_id in subj_ids]\n",
    "# all_behav,drops_data = format_all_behav(raw_behav,return_drops=True)\n",
    "\n",
    "# all_behav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6342b194-d8ac-40ef-b0a9-f1d9ca362306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_behav = [pd.read_csv(f'{behav_dir}{subj_id}_task_df.csv') for subj_id in subj_ids]\n",
    "# temp_behav,beh_drops = format_all_behav(raw_behav,return_drops=True,norm=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c819c072-47b1-44a8-b0e6-2c1a106c837a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_orthog_rpe  = []\n",
    "# all_rpe_cpe_rsq = []\n",
    "# behav_list = []\n",
    "\n",
    "# for ix, subj_id in enumerate(subj_ids): \n",
    "# #     subj_df = raw_behav[ix]\n",
    "#     subj_df = temp_behav[temp_behav.subj_id==subj_id].reset_index(drop=True)\n",
    "#     # find indices where cpe is not nan\n",
    "#     notnan_idx = [ix for ix,cpe in enumerate(subj_df.cpe) if not np.isnan(cpe)]\n",
    "#     # initialize save vector\n",
    "#     subj_df['orthog_rpe'] = np.nan\n",
    "#     # run ols regression rpe ~ cpe\n",
    "#     rpe_cpe = sm.OLS(subj_df.rpe,sm.add_constant(subj_df.cpe),missing='drop').fit()\n",
    "#     all_rpe_cpe_rsq.append(rpe_cpe.rsquared)\n",
    "#     subj_df['orthog_rpe'][notnan_idx] = rpe_cpe.resid\n",
    "#     all_orthog_rpe.extend(subj_df['orthog_rpe'])\n",
    "#     behav_list.append(subj_df)\n",
    "#     del rpe_cpe \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8645a5b0-e94e-4930-aeb0-b27edfb99738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_behav,beh_drops = format_all_behav(behav_list,return_drops=True,norm=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7b52d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_behav.to_csv(f'{save_dir}all_behav_{band}_coh_{date}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be6031fc-d22e-42dc-8133-f89eea72d196",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_behav = pd.read_csv(f'{save_dir}all_behav_theta_coh_11192024.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74b628a5-c0a2-4a95-9dca-ff1d7240684c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subj_id</th>\n",
       "      <th>bdi</th>\n",
       "      <th>bdi_thresh</th>\n",
       "      <th>Round</th>\n",
       "      <th>TrialNum</th>\n",
       "      <th>RT</th>\n",
       "      <th>TrialOnset</th>\n",
       "      <th>ChoiceOnset</th>\n",
       "      <th>DecisionOnset</th>\n",
       "      <th>FeedbackOnset</th>\n",
       "      <th>...</th>\n",
       "      <th>TrialEV_t1</th>\n",
       "      <th>CR_t1</th>\n",
       "      <th>choiceEV_t1</th>\n",
       "      <th>rpe_t1</th>\n",
       "      <th>res_type_t1</th>\n",
       "      <th>cf_t1</th>\n",
       "      <th>cpe_t1</th>\n",
       "      <th>keep_epoch</th>\n",
       "      <th>keep_epoch_t1</th>\n",
       "      <th>orthog_rpe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MS002</td>\n",
       "      <td>14</td>\n",
       "      <td>low</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.059852</td>\n",
       "      <td>513.380590</td>\n",
       "      <td>513.390239</td>\n",
       "      <td>515.450091</td>\n",
       "      <td>515.457173</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.423529</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.545852</td>\n",
       "      <td>-0.553325</td>\n",
       "      <td>gamble_bad</td>\n",
       "      <td>-0.150761</td>\n",
       "      <td>-0.450578</td>\n",
       "      <td>keep</td>\n",
       "      <td>keep</td>\n",
       "      <td>0.213638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MS002</td>\n",
       "      <td>14</td>\n",
       "      <td>low</td>\n",
       "      <td>2</td>\n",
       "      <td>117.0</td>\n",
       "      <td>1.954564</td>\n",
       "      <td>522.640856</td>\n",
       "      <td>522.641563</td>\n",
       "      <td>524.596127</td>\n",
       "      <td>526.627092</td>\n",
       "      <td>...</td>\n",
       "      <td>0.737993</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.495438</td>\n",
       "      <td>0.954543</td>\n",
       "      <td>gamble_good</td>\n",
       "      <td>0.277858</td>\n",
       "      <td>0.728779</td>\n",
       "      <td>keep</td>\n",
       "      <td>keep</td>\n",
       "      <td>-0.383128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MS002</td>\n",
       "      <td>14</td>\n",
       "      <td>low</td>\n",
       "      <td>3</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1.583462</td>\n",
       "      <td>531.174799</td>\n",
       "      <td>531.175599</td>\n",
       "      <td>532.759061</td>\n",
       "      <td>534.780269</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152000</td>\n",
       "      <td>0.090121</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.008658</td>\n",
       "      <td>safe_good</td>\n",
       "      <td>-0.456918</td>\n",
       "      <td>0.435467</td>\n",
       "      <td>keep</td>\n",
       "      <td>keep</td>\n",
       "      <td>0.684004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MS002</td>\n",
       "      <td>14</td>\n",
       "      <td>low</td>\n",
       "      <td>4</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2.491611</td>\n",
       "      <td>545.592613</td>\n",
       "      <td>545.593355</td>\n",
       "      <td>548.084966</td>\n",
       "      <td>548.092333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.619399</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.321229</td>\n",
       "      <td>0.702276</td>\n",
       "      <td>gamble_good</td>\n",
       "      <td>0.339089</td>\n",
       "      <td>0.398803</td>\n",
       "      <td>keep</td>\n",
       "      <td>keep</td>\n",
       "      <td>-0.255425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MS002</td>\n",
       "      <td>14</td>\n",
       "      <td>low</td>\n",
       "      <td>5</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1.768936</td>\n",
       "      <td>555.337336</td>\n",
       "      <td>555.345720</td>\n",
       "      <td>557.114656</td>\n",
       "      <td>559.135069</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.116581</td>\n",
       "      <td>0.090121</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.008658</td>\n",
       "      <td>safe_good</td>\n",
       "      <td>-0.640612</td>\n",
       "      <td>0.618787</td>\n",
       "      <td>keep</td>\n",
       "      <td>keep</td>\n",
       "      <td>0.579806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4045</th>\n",
       "      <td>DA039</td>\n",
       "      <td>22</td>\n",
       "      <td>high</td>\n",
       "      <td>146</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1.079701</td>\n",
       "      <td>2259.827656</td>\n",
       "      <td>2259.828749</td>\n",
       "      <td>2260.908450</td>\n",
       "      <td>2262.926195</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.297739</td>\n",
       "      <td>0.343221</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007477</td>\n",
       "      <td>safe_good</td>\n",
       "      <td>-1.253105</td>\n",
       "      <td>0.916364</td>\n",
       "      <td>keep</td>\n",
       "      <td>keep</td>\n",
       "      <td>0.279076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4046</th>\n",
       "      <td>DA039</td>\n",
       "      <td>22</td>\n",
       "      <td>high</td>\n",
       "      <td>147</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.837272</td>\n",
       "      <td>2267.502359</td>\n",
       "      <td>2267.534059</td>\n",
       "      <td>2269.371331</td>\n",
       "      <td>2269.377701</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014213</td>\n",
       "      <td>0.343221</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007477</td>\n",
       "      <td>safe_bad</td>\n",
       "      <td>0.356530</td>\n",
       "      <td>-0.300100</td>\n",
       "      <td>keep</td>\n",
       "      <td>keep</td>\n",
       "      <td>-0.947095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4047</th>\n",
       "      <td>DA039</td>\n",
       "      <td>22</td>\n",
       "      <td>high</td>\n",
       "      <td>148</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.030006</td>\n",
       "      <td>2282.349445</td>\n",
       "      <td>2282.350662</td>\n",
       "      <td>2286.380667</td>\n",
       "      <td>2286.389886</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.115722</td>\n",
       "      <td>0.343221</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007477</td>\n",
       "      <td>safe_bad</td>\n",
       "      <td>0.364957</td>\n",
       "      <td>-0.306469</td>\n",
       "      <td>keep</td>\n",
       "      <td>keep</td>\n",
       "      <td>0.336081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4048</th>\n",
       "      <td>DA039</td>\n",
       "      <td>22</td>\n",
       "      <td>high</td>\n",
       "      <td>149</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.167144</td>\n",
       "      <td>2293.040983</td>\n",
       "      <td>2293.042042</td>\n",
       "      <td>2296.209186</td>\n",
       "      <td>2296.218136</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.032806</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.312281</td>\n",
       "      <td>-1.093440</td>\n",
       "      <td>gamble_bad</td>\n",
       "      <td>-0.410364</td>\n",
       "      <td>-1.312759</td>\n",
       "      <td>keep</td>\n",
       "      <td>keep</td>\n",
       "      <td>0.342799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4049</th>\n",
       "      <td>DA039</td>\n",
       "      <td>22</td>\n",
       "      <td>high</td>\n",
       "      <td>150</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3.208672</td>\n",
       "      <td>2303.711312</td>\n",
       "      <td>2303.712405</td>\n",
       "      <td>2306.921076</td>\n",
       "      <td>2308.938158</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>keep</td>\n",
       "      <td>drop</td>\n",
       "      <td>-0.200444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4050 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     subj_id  bdi bdi_thresh  Round  TrialNum        RT   TrialOnset  \\\n",
       "0      MS002   14        low      1      25.0  2.059852   513.380590   \n",
       "1      MS002   14        low      2     117.0  1.954564   522.640856   \n",
       "2      MS002   14        low      3      79.0  1.583462   531.174799   \n",
       "3      MS002   14        low      4      42.0  2.491611   545.592613   \n",
       "4      MS002   14        low      5      85.0  1.768936   555.337336   \n",
       "...      ...  ...        ...    ...       ...       ...          ...   \n",
       "4045   DA039   22       high    146      79.0  1.079701  2259.827656   \n",
       "4046   DA039   22       high    147      30.0  1.837272  2267.502359   \n",
       "4047   DA039   22       high    148      13.0  4.030006  2282.349445   \n",
       "4048   DA039   22       high    149      18.0  3.167144  2293.040983   \n",
       "4049   DA039   22       high    150     140.0  3.208672  2303.711312   \n",
       "\n",
       "      ChoiceOnset  DecisionOnset  FeedbackOnset  ... TrialEV_t1     CR_t1  \\\n",
       "0      513.390239     515.450091     515.457173  ...  -0.423529       NaN   \n",
       "1      522.641563     524.596127     526.627092  ...   0.737993       NaN   \n",
       "2      531.175599     532.759061     534.780269  ...   0.152000  0.090121   \n",
       "3      545.593355     548.084966     548.092333  ...   0.619399       NaN   \n",
       "4      555.345720     557.114656     559.135069  ...  -0.116581  0.090121   \n",
       "...           ...            ...            ...  ...        ...       ...   \n",
       "4045  2259.828749    2260.908450    2262.926195  ...  -0.297739  0.343221   \n",
       "4046  2267.534059    2269.371331    2269.377701  ...  -0.014213  0.343221   \n",
       "4047  2282.350662    2286.380667    2286.389886  ...  -0.115722  0.343221   \n",
       "4048  2293.042042    2296.209186    2296.218136  ...  -1.032806       NaN   \n",
       "4049  2303.712405    2306.921076    2308.938158  ...        NaN       NaN   \n",
       "\n",
       "      choiceEV_t1    rpe_t1  res_type_t1     cf_t1    cpe_t1  keep_epoch  \\\n",
       "0       -0.545852 -0.553325   gamble_bad -0.150761 -0.450578        keep   \n",
       "1        0.495438  0.954543  gamble_good  0.277858  0.728779        keep   \n",
       "2             NaN -0.008658    safe_good -0.456918  0.435467        keep   \n",
       "3        0.321229  0.702276  gamble_good  0.339089  0.398803        keep   \n",
       "4             NaN -0.008658    safe_good -0.640612  0.618787        keep   \n",
       "...           ...       ...          ...       ...       ...         ...   \n",
       "4045          NaN  0.007477    safe_good -1.253105  0.916364        keep   \n",
       "4046          NaN  0.007477     safe_bad  0.356530 -0.300100        keep   \n",
       "4047          NaN  0.007477     safe_bad  0.364957 -0.306469        keep   \n",
       "4048    -1.312281 -1.093440   gamble_bad -0.410364 -1.312759        keep   \n",
       "4049          NaN       NaN          NaN       NaN       NaN        keep   \n",
       "\n",
       "      keep_epoch_t1  orthog_rpe  \n",
       "0              keep    0.213638  \n",
       "1              keep   -0.383128  \n",
       "2              keep    0.684004  \n",
       "3              keep   -0.255425  \n",
       "4              keep    0.579806  \n",
       "...             ...         ...  \n",
       "4045           keep    0.279076  \n",
       "4046           keep   -0.947095  \n",
       "4047           keep    0.336081  \n",
       "4048           keep    0.342799  \n",
       "4049           drop   -0.200444  \n",
       "\n",
       "[4050 rows x 53 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_behav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbcf4065-79bd-4658-82cf-061eb66e476e",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_reref_labels_master_df = pd.read_csv(\n",
    "    glob(f'{base_dir}ephys_analysis/results/roi_info/roi_reref_labels_master.csv')[0]).drop(columns=['Unnamed: 0'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9019470-f983-46fd-b09b-ce2ef462cafb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'theta'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "band"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d880360",
   "metadata": {},
   "source": [
    "# Connectivity Computations : Theta Coherence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5afc6fc-ed52-47d2-9e05-7f34ecdce18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define connectivity analysis parameters:\n",
    "\n",
    "# spectral parameters - wavelet freqs, wavelet cycles, freq band ranges\n",
    "freqs = np.logspace(*np.log10([2, 200]), num=30)\n",
    "n_cycles = np.floor(np.logspace(*np.log10([3, 10]), num=30))\n",
    "\n",
    "freq_dict = {'theta':[4, 8], \n",
    "             'alpha':[8, 13],\n",
    "             'beta': [13, 30], \n",
    "             'gamma': [30,70],\n",
    "             'hfa': [70, 200]}\n",
    "\n",
    "# analysis parameters - connectivity metric, conn freq band, num of surrogates for permutations, buffer time in ms\n",
    "metric   = 'coh'\n",
    "band     = 'theta' # set band(s) of interest for analysis\n",
    "n_surr   = 500\n",
    "buf_ms   = 1000\n",
    "\n",
    "# data info - analysis epoch + rois for pairwise coh\n",
    "epoch_id = 'CpeOnset' \n",
    "# rois\n",
    "coh_rois = ['acc','ains','ofc','dlpfc','vlpfc','amy','dmpfc','hpc']\n",
    "\n",
    "# dict of subj_ids with elecs in roi \n",
    "roi_subj_ids = {f'{roi}':roi_reref_labels_master_df.subj_id[\n",
    "    roi_reref_labels_master_df.roi == roi].unique().tolist() \n",
    "                for roi in coh_rois}\n",
    "# # make unique list of pairs [[pair1,pair2],..] without hard coding \n",
    "# pairs = [list(tup) for tup in list(itertools.combinations(coh_rois,2))]\n",
    "# pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43bde499-1c40-473b-8917-970547d4de96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['acc', 'ains'],\n",
       " ['acc', 'ofc'],\n",
       " ['acc', 'dlpfc'],\n",
       " ['acc', 'vlpfc'],\n",
       " ['acc', 'amy'],\n",
       " ['acc', 'dmpfc'],\n",
       " ['acc', 'hpc'],\n",
       " ['ains', 'ofc'],\n",
       " ['ains', 'dlpfc'],\n",
       " ['ains', 'vlpfc'],\n",
       " ['ains', 'amy'],\n",
       " ['ains', 'dmpfc'],\n",
       " ['ains', 'hpc'],\n",
       " ['ofc', 'dlpfc'],\n",
       " ['ofc', 'vlpfc'],\n",
       " ['ofc', 'amy'],\n",
       " ['ofc', 'dmpfc'],\n",
       " ['ofc', 'hpc'],\n",
       " ['dlpfc', 'vlpfc'],\n",
       " ['dlpfc', 'amy'],\n",
       " ['dlpfc', 'dmpfc'],\n",
       " ['dlpfc', 'hpc'],\n",
       " ['vlpfc', 'amy'],\n",
       " ['vlpfc', 'dmpfc'],\n",
       " ['vlpfc', 'hpc'],\n",
       " ['amy', 'dmpfc'],\n",
       " ['amy', 'hpc'],\n",
       " ['dmpfc', 'hpc']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_combos = [list(tup) for tup in list(itertools.combinations(coh_rois,2))]\n",
    "all_combos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e204bc39-fe56-4603-8ca7-6f547925a226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['dlpfc', 'amy'],\n",
       " ['ains', 'amy'],\n",
       " ['acc', 'amy'],\n",
       " ['ofc', 'dlpfc'],\n",
       " ['acc', 'ains'],\n",
       " ['acc', 'dlpfc'],\n",
       " ['ofc', 'amy'],\n",
       " ['ains', 'dmpfc'],\n",
       " ['acc', 'dmpfc'],\n",
       " ['ains', 'dlpfc'],\n",
       " ['ains', 'vlpfc'],\n",
       " ['acc', 'vlpfc'],\n",
       " ['ains', 'ofc'],\n",
       " ['acc', 'ofc'],\n",
       " ['ofc', 'dmpfc']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finished_pairs = [file.split('_')[:2] for file in os.listdir(f'{save_dir}pair_data/')]\n",
    "finished_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56ff1cc9-2632-43fc-929b-9828b75a4452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['amy', 'dmpfc']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ## unique list of all pairs that have any single subjects saved \n",
    "all_pair_files = [file.split('_')[1:3] for file in os.listdir(f'{save_dir}single_subj/') if file.split('_')[-1] == 'df.csv']\n",
    "all_pair_files\n",
    "\n",
    "pair_subj_data = []\n",
    "for pair in all_pair_files:\n",
    "    if pair not in pair_subj_data:\n",
    "        pair_subj_data.append(pair)\n",
    "pair_subj_data\n",
    "\n",
    "# # find which pairs weren't completed \n",
    "incomplete_pairs = [pair for pair in pair_subj_data if pair not in finished_pairs]\n",
    "incomplete_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88509329-bce6-497f-9500-92f248b629cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_subj_dict   = {}\n",
    "incomplete_subj_dict = {}\n",
    "\n",
    "for pair in incomplete_pairs:\n",
    "    source_region = pair[0]\n",
    "    target_region = pair[1]    \n",
    "    # unique pair id roi1_roi2\n",
    "    pair_id = '_'.join([source_region,target_region])\n",
    "\n",
    "    # find subj with elecs in each roi \n",
    "    source_subj = roi_subj_ids[source_region]\n",
    "    target_subj = roi_subj_ids[target_region]\n",
    "    \n",
    "    # # find subj with elecs in both rois\n",
    "    pair_subj = list(set(source_subj).intersection(target_subj))    \n",
    "    # # find completed subj files\n",
    "    complete_subj_files = glob(f'{save_dir}single_subj/*{pair_id}_coh_{band}_df.csv')\n",
    "    complete_subj = [file.split('/')[-1].split('_')[0] for file in complete_subj_files]\n",
    "    complete_subj_dict[pair_id] = complete_subj\n",
    "\n",
    "    # # find subj from pair_subj with no saved data\n",
    "    incomplete_subj = list(np.setdiff1d(pair_subj, complete_subj))\n",
    "    incomplete_subj_dict[pair_id] = incomplete_subj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "834ed7cb-447e-4d75-8185-d7c70a0e50b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['acc', 'hpc'],\n",
       " ['ains', 'hpc'],\n",
       " ['ofc', 'vlpfc'],\n",
       " ['ofc', 'hpc'],\n",
       " ['dlpfc', 'vlpfc'],\n",
       " ['dlpfc', 'dmpfc'],\n",
       " ['dlpfc', 'hpc'],\n",
       " ['vlpfc', 'amy'],\n",
       " ['vlpfc', 'dmpfc'],\n",
       " ['vlpfc', 'hpc'],\n",
       " ['amy', 'hpc'],\n",
       " ['dmpfc', 'hpc']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_pairs = [pair for pair in all_combos if (pair not in finished_pairs) & (pair not in incomplete_pairs)]\n",
    "run_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39af1744-24c5-424b-b062-1bf374bd6918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['amy', 'dmpfc'],\n",
       " ['acc', 'hpc'],\n",
       " ['ains', 'hpc'],\n",
       " ['ofc', 'vlpfc'],\n",
       " ['ofc', 'hpc'],\n",
       " ['dlpfc', 'vlpfc'],\n",
       " ['dlpfc', 'dmpfc'],\n",
       " ['dlpfc', 'hpc'],\n",
       " ['vlpfc', 'amy'],\n",
       " ['vlpfc', 'dmpfc'],\n",
       " ['vlpfc', 'hpc'],\n",
       " ['amy', 'hpc'],\n",
       " ['dmpfc', 'hpc']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add incomplete pair to beginning of list to run first \n",
    "pairs = incomplete_pairs + run_pairs\n",
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "436d04d6-0d40-47f3-bfb7-b312d32afed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['dlpfc', 'hpc'],\n",
       " ['amy', 'hpc'],\n",
       " ['dmpfc', 'hpc'],\n",
       " ['vlpfc', 'hpc'],\n",
       " ['vlpfc', 'dmpfc'],\n",
       " ['dlpfc', 'vlpfc'],\n",
       " ['dlpfc', 'dmpfc']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### running 2nd half of pairs in parallel with main notebook doing first half - drop any in progress pairs \n",
    "\n",
    "pairs = [['dlpfc', 'hpc'],\n",
    "         ['amy', 'hpc'],\n",
    "         ['dmpfc', 'hpc'],\n",
    "         ['vlpfc', 'hpc'],\n",
    "         ['vlpfc', 'dmpfc'],\n",
    "         ['dlpfc', 'vlpfc'],\n",
    "         ['dlpfc', 'dmpfc']]\n",
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b34132b-7f0b-4d97-ab52-420b9a4eac4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /sc/arion/projects/guLab/Alie/SWB/ephys_analysis/data/MS033/MS033_conn_epochs_CpeOnset.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    2000.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "150 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n"
     ]
    }
   ],
   "source": [
    "######## to compute coh after notebook ends in middle of roi pair\n",
    "\n",
    "for pair in pairs:\n",
    "    \n",
    "    source_region = pair[0]\n",
    "    target_region = pair[1]    \n",
    "    \n",
    "    # unique pair id roi1_roi2\n",
    "    pair_id = '_'.join([source_region,target_region])\n",
    "    \n",
    "    # find subj with elecs in each roi \n",
    "    source_subj = roi_subj_ids[source_region]\n",
    "    target_subj = roi_subj_ids[target_region]\n",
    "    # find subj with elecs in both rois\n",
    "    pair_subj = list(set(source_subj).intersection(target_subj))    \n",
    "    # save pair subj list \n",
    "\n",
    "    if pair in incomplete_pairs:\n",
    "        complete_subj   = complete_subj_dict[pair_id]\n",
    "        incomplete_subj = incomplete_subj_dict[pair_id]\n",
    "    \n",
    "    # initialize the storage list \n",
    "    all_subj_pair_df = []\n",
    "    \n",
    "    # iterate through pair subjects\n",
    "    for subj_id in pair_subj:\n",
    "        \n",
    "        if pair in incomplete_pairs:\n",
    "            if subj_id in complete_subj:\n",
    "                continue\n",
    "                \n",
    "        # load & format rereferenced epoch data \n",
    "        subj_epochs = mne.read_epochs(f'{neural_dir}{subj_id}/{subj_id}_conn_epochs_{epoch_id}.fif', preload=True)\n",
    "        subj_elecs  = subj_epochs.ch_names\n",
    "        \n",
    "        # construct the seed-to-target mapping based on subject's roi coverage \n",
    "        elec_roi_df = roi_reref_labels_master_df[roi_reref_labels_master_df.subj_id==subj_id].reset_index(drop=True)\n",
    "        # get ch names of subj elecs in roi \n",
    "        source_ch_names  = elec_roi_df.reref_ch_names[np.where(elec_roi_df.roi == source_region)[0]].tolist()\n",
    "        target_ch_names  = elec_roi_df.reref_ch_names[np.where(elec_roi_df.roi == target_region)[0]].tolist()\n",
    "        # get idx of ch in subj_elecs list (will correspond to idx in epochs array)\n",
    "        source_elec_idx = [subj_elecs.index(elec) for elec in source_ch_names]\n",
    "        target_elec_idx = [subj_elecs.index(elec) for elec in target_ch_names]\n",
    "        # make seed to target indices using mne function \n",
    "        seed_to_target = seed_target_indices(\n",
    "                        source_elec_idx,\n",
    "                        target_elec_idx)\n",
    "        \n",
    "        # elec name for every elec pair \n",
    "        subj_pair_ch = list(map(lambda x,y: '_'.join([x,y]), \n",
    "                                  [subj_elecs[idx] for idx in  seed_to_target[0]], \n",
    "                                  [subj_elecs[idx] for idx in  seed_to_target[1]]))\n",
    "        # unique elec name for every elec pair \n",
    "        unique_ch_pair = list(map(lambda x,y: '_'.join([x,y]), [subj_id]*len(subj_pair_ch), subj_pair_ch))\n",
    "        \n",
    "        # compute pwise coherence \n",
    "        pwise = oscillation_utils.compute_connectivity(subj_epochs, \n",
    "                                           band = freq_dict[band], \n",
    "                                           metric = metric, \n",
    "                                           indices = seed_to_target, \n",
    "                                           freqs = freqs, \n",
    "                                           n_cycles = n_cycles,\n",
    "                                           buf_ms = buf_ms, \n",
    "                                           n_surr=n_surr,\n",
    "                                           avg_over_dim='time',\n",
    "                                           band1 = freq_dict[band],\n",
    "                                           parallelize=True)\n",
    "\n",
    "        \n",
    "        coh_df = pd.concat([pd.DataFrame({'epoch':np.arange(0,pwise.shape[0]),'coh':pwise[:,ch_ix],\n",
    "                                          'unique_ch_pair':[ch_name]*pwise.shape[0],\n",
    "                                          'roi_pair_chans':['_'.join(ch_name.split('_')[1:])]*pwise.shape[0],\n",
    "                                          'roi1_ch_names':[ch_name.split('_')[1]]*pwise.shape[0],\n",
    "                                          'roi2_ch_names':[ch_name.split('_')[2]]*pwise.shape[0],\n",
    "                                          'roi1_elec_idx':[seed_to_target[0]]*pwise.shape[0],\n",
    "                                          'roi2_elec_idx':[seed_to_target[1]]*pwise.shape[0]}) \n",
    "                            for ch_ix, ch_name in enumerate(unique_ch_pair)])\n",
    "\n",
    "\n",
    "\n",
    "        coh_df['subj_id']  = subj_id\n",
    "        coh_df['bdi']      = all_behav[all_behav.subj_id == subj_id].bdi.unique().tolist()[0]\n",
    "        coh_df['Round']    = all_behav[all_behav.subj_id == subj_id].Round\n",
    "        coh_df['epoch']    = all_behav[all_behav.subj_id == subj_id].epoch\n",
    "        coh_df['band']     = band\n",
    "        coh_df['metric']   = metric\n",
    "        coh_df['pair_id']  = pair_id\n",
    "        coh_df['roi1']     = source_region\n",
    "        coh_df['roi2']     = target_region\n",
    "\n",
    "\n",
    "        # one pair one subj data \n",
    "        coh_df.to_csv(f'{save_dir}single_subj/{subj_id}_{pair_id}_{metric}_{band}_df.csv')\n",
    "        all_subj_pair_df.append(coh_df)\n",
    "        del coh_df, subj_epochs, pwise\n",
    "#         print(f'finished {subj_id} {pair_id}')\n",
    "    \n",
    "    \n",
    "    # # add completed subj dfs to concat list \n",
    "    if pair in incomplete_pairs:\n",
    "        for subj_id in complete_subj:\n",
    "            subj_df = pd.read_csv(f'{save_dir}single_subj/{subj_id}_{pair_id}_{metric}_{band}_df.csv')\n",
    "            all_subj_pair_df.append(subj_df)\n",
    "            del subj_df   \n",
    "        \n",
    "    all_subj_pair_df = pd.concat(all_subj_pair_df).reset_index()\n",
    "    # save roi pair df separately \n",
    "    all_subj_pair_df.to_csv(f'{save_dir}pair_data/{pair_id}_{metric}_{band}_df.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaca4c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670a5689",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swb_lfp",
   "language": "python",
   "name": "swb_lfp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
