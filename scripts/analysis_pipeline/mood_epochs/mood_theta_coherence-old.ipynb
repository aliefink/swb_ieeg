{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63c15ef6",
   "metadata": {},
   "source": [
    "# SWB Connectivity Analysis: Theta Coherence During Mood Rating\n",
    "\n",
    "Created: 08/22/2024 \\\n",
    "Updated: 10/06/2024 \\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82b06ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mne\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import seaborn as sns\n",
    "from scipy.stats import zscore, linregress, ttest_ind, ttest_rel, ttest_1samp, pearsonr, spearmanr\n",
    "import pandas as pd\n",
    "from mne.preprocessing.bads import _find_outliers\n",
    "import os \n",
    "import joblib\n",
    "import re\n",
    "import datetime\n",
    "import scipy\n",
    "import random\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.regression.mixed_linear_model import MixedLM \n",
    "from joblib import Parallel, delayed\n",
    "import pickle\n",
    "import itertools\n",
    "import time \n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "\n",
    "\n",
    "import mne_connectivity\n",
    "from mne_connectivity import phase_slope_index, seed_target_indices, spectral_connectivity_epochs\n",
    "# import fooof\n",
    "# Import plotting functions\n",
    "# from fooof.plts.spectra import plot_spectrum, plot_spectra\n",
    "# # Import the FOOOF object\n",
    "# from fooof import FOOOF\n",
    "# from fooof import FOOOFGroup\n",
    "\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from joblib import delayed, Parallel\n",
    "from statsmodels.stats import multitest\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# print('\\n'.join(f'{m.__name__}=={m.__version__}' for m in globals().values() if getattr(m, '__version__', None)))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e13b8c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10062024\n"
     ]
    }
   ],
   "source": [
    "# Specify root directory for un-archived data and results \n",
    "base_dir   = '/sc/arion/projects/guLab/Alie/SWB/ephys_analysis/'\n",
    "neural_dir = f'{base_dir}data/'\n",
    "behav_dir  = f'{base_dir}behav/behav_data/'\n",
    "save_dir   = f'{base_dir}results/mood_results/coherence/theta/'\n",
    "os.makedirs(save_dir,exist_ok=True)\n",
    "\n",
    "\n",
    "save_subj_dir = f'{base_dir}results/mood_results/coherence/theta/single_subj/'\n",
    "os.makedirs(save_subj_dir,exist_ok=True)\n",
    "\n",
    "script_dir = '/hpc/users/finka03/swb_ephys_analysis/scripts/'\n",
    "\n",
    "date = datetime.date.today().strftime('%m%d%Y')\n",
    "print(date)\n",
    "\n",
    "# anat_dir   = f'{base_dir}ephys_analysis/recon_labels/'\n",
    "# behav_dir  = f'{base_dir}swb_behav_models/data/behavior_preprocessed/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ebfd527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(f'{base_dir}LFPAnalysis/')\n",
    "\n",
    "from LFPAnalysis import analysis_utils,oscillation_utils\n",
    "\n",
    "sys.path.append(f'{script_dir}analysis_notebooks/')\n",
    "\n",
    "from ieeg_tools import *\n",
    "\n",
    "sys.path.append(f'{script_dir}behav/')\n",
    "\n",
    "from behav_utils import *\n",
    "from swb_subj_behav import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9316f53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_ids = list(pd.read_excel(f'{base_dir}subj_info/SWB_subjects.xlsx', \n",
    "                              sheet_name='Usable_Subjects', usecols=[0]).PatientID)\n",
    "n_subj = len(subj_ids)\n",
    "# subj_ids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fb5f14-a38b-477e-8ebd-5f0b67a60f96",
   "metadata": {},
   "source": [
    "# Load Behav + Elec ROI Data\n",
    "- all_behav from updated task_dfs and behav_utils formatting\n",
    "- roi_reref_labels same as usual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30605ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subj_id</th>\n",
       "      <th>bdi</th>\n",
       "      <th>bdi_thresh</th>\n",
       "      <th>Round</th>\n",
       "      <th>TrialNum</th>\n",
       "      <th>RT</th>\n",
       "      <th>TrialOnset</th>\n",
       "      <th>ChoiceOnset</th>\n",
       "      <th>DecisionOnset</th>\n",
       "      <th>FeedbackOnset</th>\n",
       "      <th>...</th>\n",
       "      <th>GambleEV_t1</th>\n",
       "      <th>TrialEV_t1</th>\n",
       "      <th>CR_t1</th>\n",
       "      <th>choiceEV_t1</th>\n",
       "      <th>rpe_t1</th>\n",
       "      <th>res_type_t1</th>\n",
       "      <th>cf_t1</th>\n",
       "      <th>cpe_t1</th>\n",
       "      <th>keep_epoch</th>\n",
       "      <th>keep_epoch_t1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MS002</td>\n",
       "      <td>14</td>\n",
       "      <td>low</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.059852</td>\n",
       "      <td>513.380590</td>\n",
       "      <td>513.390239</td>\n",
       "      <td>515.450091</td>\n",
       "      <td>515.457173</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.411450</td>\n",
       "      <td>-0.423529</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.545852</td>\n",
       "      <td>-0.553325</td>\n",
       "      <td>gamble_bad</td>\n",
       "      <td>-0.150761</td>\n",
       "      <td>-0.450578</td>\n",
       "      <td>keep</td>\n",
       "      <td>keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MS002</td>\n",
       "      <td>14</td>\n",
       "      <td>low</td>\n",
       "      <td>2</td>\n",
       "      <td>117.0</td>\n",
       "      <td>1.954564</td>\n",
       "      <td>522.640856</td>\n",
       "      <td>522.641563</td>\n",
       "      <td>524.596127</td>\n",
       "      <td>526.627092</td>\n",
       "      <td>...</td>\n",
       "      <td>0.772187</td>\n",
       "      <td>0.737993</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.495438</td>\n",
       "      <td>0.954543</td>\n",
       "      <td>gamble_good</td>\n",
       "      <td>0.277858</td>\n",
       "      <td>0.728779</td>\n",
       "      <td>keep</td>\n",
       "      <td>keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MS002</td>\n",
       "      <td>14</td>\n",
       "      <td>low</td>\n",
       "      <td>3</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1.583462</td>\n",
       "      <td>531.174799</td>\n",
       "      <td>531.175599</td>\n",
       "      <td>532.759061</td>\n",
       "      <td>534.780269</td>\n",
       "      <td>...</td>\n",
       "      <td>0.196120</td>\n",
       "      <td>0.152000</td>\n",
       "      <td>0.090121</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.008658</td>\n",
       "      <td>safe_good</td>\n",
       "      <td>-0.456918</td>\n",
       "      <td>0.435467</td>\n",
       "      <td>keep</td>\n",
       "      <td>keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MS002</td>\n",
       "      <td>14</td>\n",
       "      <td>low</td>\n",
       "      <td>4</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2.491611</td>\n",
       "      <td>545.592613</td>\n",
       "      <td>545.593355</td>\n",
       "      <td>548.084966</td>\n",
       "      <td>548.092333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.574164</td>\n",
       "      <td>0.619399</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.321229</td>\n",
       "      <td>0.702276</td>\n",
       "      <td>gamble_good</td>\n",
       "      <td>0.339089</td>\n",
       "      <td>0.398803</td>\n",
       "      <td>keep</td>\n",
       "      <td>keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MS002</td>\n",
       "      <td>14</td>\n",
       "      <td>low</td>\n",
       "      <td>5</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1.768936</td>\n",
       "      <td>555.337336</td>\n",
       "      <td>555.345720</td>\n",
       "      <td>557.114656</td>\n",
       "      <td>559.135069</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.150420</td>\n",
       "      <td>-0.116581</td>\n",
       "      <td>0.090121</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.008658</td>\n",
       "      <td>safe_good</td>\n",
       "      <td>-0.640612</td>\n",
       "      <td>0.618787</td>\n",
       "      <td>keep</td>\n",
       "      <td>keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4045</th>\n",
       "      <td>DA039</td>\n",
       "      <td>22</td>\n",
       "      <td>high</td>\n",
       "      <td>146</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1.079701</td>\n",
       "      <td>2259.827656</td>\n",
       "      <td>2259.828749</td>\n",
       "      <td>2260.908450</td>\n",
       "      <td>2262.926195</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.385065</td>\n",
       "      <td>-0.297739</td>\n",
       "      <td>0.343221</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007477</td>\n",
       "      <td>safe_good</td>\n",
       "      <td>-1.253105</td>\n",
       "      <td>0.916364</td>\n",
       "      <td>keep</td>\n",
       "      <td>keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4046</th>\n",
       "      <td>DA039</td>\n",
       "      <td>22</td>\n",
       "      <td>high</td>\n",
       "      <td>147</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.837272</td>\n",
       "      <td>2267.502359</td>\n",
       "      <td>2267.534059</td>\n",
       "      <td>2269.371331</td>\n",
       "      <td>2269.377701</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018381</td>\n",
       "      <td>-0.014213</td>\n",
       "      <td>0.343221</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007477</td>\n",
       "      <td>safe_bad</td>\n",
       "      <td>0.356530</td>\n",
       "      <td>-0.300100</td>\n",
       "      <td>keep</td>\n",
       "      <td>keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4047</th>\n",
       "      <td>DA039</td>\n",
       "      <td>22</td>\n",
       "      <td>high</td>\n",
       "      <td>148</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.030006</td>\n",
       "      <td>2282.349445</td>\n",
       "      <td>2282.350662</td>\n",
       "      <td>2286.380667</td>\n",
       "      <td>2286.389886</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.149663</td>\n",
       "      <td>-0.115722</td>\n",
       "      <td>0.343221</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007477</td>\n",
       "      <td>safe_bad</td>\n",
       "      <td>0.364957</td>\n",
       "      <td>-0.306469</td>\n",
       "      <td>keep</td>\n",
       "      <td>keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4048</th>\n",
       "      <td>DA039</td>\n",
       "      <td>22</td>\n",
       "      <td>high</td>\n",
       "      <td>149</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.167144</td>\n",
       "      <td>2293.040983</td>\n",
       "      <td>2293.042042</td>\n",
       "      <td>2296.209186</td>\n",
       "      <td>2296.218136</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.109379</td>\n",
       "      <td>-1.032806</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.312281</td>\n",
       "      <td>-1.093440</td>\n",
       "      <td>gamble_bad</td>\n",
       "      <td>-0.410364</td>\n",
       "      <td>-1.312759</td>\n",
       "      <td>keep</td>\n",
       "      <td>keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4049</th>\n",
       "      <td>DA039</td>\n",
       "      <td>22</td>\n",
       "      <td>high</td>\n",
       "      <td>150</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3.208672</td>\n",
       "      <td>2303.711312</td>\n",
       "      <td>2303.712405</td>\n",
       "      <td>2306.921076</td>\n",
       "      <td>2308.938158</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>keep</td>\n",
       "      <td>drop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4050 rows Ã— 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     subj_id  bdi bdi_thresh  Round  TrialNum        RT   TrialOnset  \\\n",
       "0      MS002   14        low      1      25.0  2.059852   513.380590   \n",
       "1      MS002   14        low      2     117.0  1.954564   522.640856   \n",
       "2      MS002   14        low      3      79.0  1.583462   531.174799   \n",
       "3      MS002   14        low      4      42.0  2.491611   545.592613   \n",
       "4      MS002   14        low      5      85.0  1.768936   555.337336   \n",
       "...      ...  ...        ...    ...       ...       ...          ...   \n",
       "4045   DA039   22       high    146      79.0  1.079701  2259.827656   \n",
       "4046   DA039   22       high    147      30.0  1.837272  2267.502359   \n",
       "4047   DA039   22       high    148      13.0  4.030006  2282.349445   \n",
       "4048   DA039   22       high    149      18.0  3.167144  2293.040983   \n",
       "4049   DA039   22       high    150     140.0  3.208672  2303.711312   \n",
       "\n",
       "      ChoiceOnset  DecisionOnset  FeedbackOnset  ... GambleEV_t1  TrialEV_t1  \\\n",
       "0      513.390239     515.450091     515.457173  ...   -0.411450   -0.423529   \n",
       "1      522.641563     524.596127     526.627092  ...    0.772187    0.737993   \n",
       "2      531.175599     532.759061     534.780269  ...    0.196120    0.152000   \n",
       "3      545.593355     548.084966     548.092333  ...    0.574164    0.619399   \n",
       "4      555.345720     557.114656     559.135069  ...   -0.150420   -0.116581   \n",
       "...           ...            ...            ...  ...         ...         ...   \n",
       "4045  2259.828749    2260.908450    2262.926195  ...   -0.385065   -0.297739   \n",
       "4046  2267.534059    2269.371331    2269.377701  ...   -0.018381   -0.014213   \n",
       "4047  2282.350662    2286.380667    2286.389886  ...   -0.149663   -0.115722   \n",
       "4048  2293.042042    2296.209186    2296.218136  ...   -1.109379   -1.032806   \n",
       "4049  2303.712405    2306.921076    2308.938158  ...         NaN         NaN   \n",
       "\n",
       "         CR_t1  choiceEV_t1    rpe_t1  res_type_t1     cf_t1    cpe_t1  \\\n",
       "0          NaN    -0.545852 -0.553325   gamble_bad -0.150761 -0.450578   \n",
       "1          NaN     0.495438  0.954543  gamble_good  0.277858  0.728779   \n",
       "2     0.090121          NaN -0.008658    safe_good -0.456918  0.435467   \n",
       "3          NaN     0.321229  0.702276  gamble_good  0.339089  0.398803   \n",
       "4     0.090121          NaN -0.008658    safe_good -0.640612  0.618787   \n",
       "...        ...          ...       ...          ...       ...       ...   \n",
       "4045  0.343221          NaN  0.007477    safe_good -1.253105  0.916364   \n",
       "4046  0.343221          NaN  0.007477     safe_bad  0.356530 -0.300100   \n",
       "4047  0.343221          NaN  0.007477     safe_bad  0.364957 -0.306469   \n",
       "4048       NaN    -1.312281 -1.093440   gamble_bad -0.410364 -1.312759   \n",
       "4049       NaN          NaN       NaN          NaN       NaN       NaN   \n",
       "\n",
       "      keep_epoch  keep_epoch_t1  \n",
       "0           keep           keep  \n",
       "1           keep           keep  \n",
       "2           keep           keep  \n",
       "3           keep           keep  \n",
       "4           keep           keep  \n",
       "...          ...            ...  \n",
       "4045        keep           keep  \n",
       "4046        keep           keep  \n",
       "4047        keep           keep  \n",
       "4048        keep           keep  \n",
       "4049        keep           drop  \n",
       "\n",
       "[4050 rows x 52 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all_behav = pd.read_csv(f'{behav_dir}all_behav.csv') ## this isn't normalized yet \n",
    "raw_behav = [pd.read_csv(f'{behav_dir}{subj_id}_task_df.csv') for subj_id in subj_ids]\n",
    "all_behav,drops_data = format_all_behav(raw_behav,return_drops=True)\n",
    "\n",
    "all_behav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5141f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_mood = [pd.read_csv(f'{behav_dir}{subj_id}_mood_df.csv') for subj_id in subj_ids]\n",
    "all_mood, mood_drops = format_all_mood(raw_mood, all_behav, return_drops=True, drop_bads=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7b52d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "band = 'theta'\n",
    "# all_behav.to_csv(f'{save_dir}all_behav_{band}_coh_{date}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef190f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_reref_labels_master_df = pd.read_csv(\n",
    "    glob(f'{base_dir}results/roi_info/roi_reref_labels_master.csv')[0]).drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# roi_reref_labels_master_df #= roi_reref_labels_master_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46b3ac01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['acc', 'amy'], ['acc', 'ains'], ['acc', 'dmpfc']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finished_pairs = [file.split('_')[:2] for file in os.listdir(f'{save_dir}') if file.split('_')[-1] == 'df.csv' ]\n",
    "finished_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d880360",
   "metadata": {},
   "source": [
    "# Connectivity Computations : Beta Coherence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc3d7b51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['acc', 'dmpfc'],\n",
       " ['acc', 'amy'],\n",
       " ['acc', 'ains'],\n",
       " ['acc', 'ofc'],\n",
       " ['acc', 'vlpfc'],\n",
       " ['acc', 'dlpfc'],\n",
       " ['acc', 'hpc'],\n",
       " ['dmpfc', 'amy'],\n",
       " ['dmpfc', 'ains'],\n",
       " ['dmpfc', 'ofc'],\n",
       " ['dmpfc', 'vlpfc'],\n",
       " ['dmpfc', 'dlpfc'],\n",
       " ['dmpfc', 'hpc'],\n",
       " ['amy', 'ains'],\n",
       " ['amy', 'ofc'],\n",
       " ['amy', 'vlpfc'],\n",
       " ['amy', 'dlpfc'],\n",
       " ['amy', 'hpc'],\n",
       " ['ains', 'ofc'],\n",
       " ['ains', 'vlpfc'],\n",
       " ['ains', 'dlpfc'],\n",
       " ['ains', 'hpc'],\n",
       " ['ofc', 'vlpfc'],\n",
       " ['ofc', 'dlpfc'],\n",
       " ['ofc', 'hpc'],\n",
       " ['vlpfc', 'dlpfc'],\n",
       " ['vlpfc', 'hpc'],\n",
       " ['dlpfc', 'hpc']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define connectivity analysis parameters:\n",
    "\n",
    "# spectral parameters - wavelet freqs, wavelet cycles, freq band ranges\n",
    "freqs = np.logspace(*np.log10([2, 200]), num=30)\n",
    "n_cycles = np.floor(np.logspace(*np.log10([3, 10]), num=30))\n",
    "\n",
    "freq_dict = {'theta':[4, 8], \n",
    "             'alpha':[8, 13],\n",
    "             'beta': [13, 30], \n",
    "             'gamma': [30,70],\n",
    "             'hfa': [70, 200]}\n",
    "\n",
    "# analysis parameters - connectivity metric, conn freq band, num of surrogates for permutations, buffer time in ms\n",
    "metric   = 'coh'\n",
    "n_surr   = 500\n",
    "buf_ms   = 1000\n",
    "\n",
    "# data info - analysis epoch + rois for pairwise coh\n",
    "epoch_id = 'MoodChoiceOnset' \n",
    "# rois\n",
    "coh_rois = ['acc','dmpfc','amy','ains','ofc','vlpfc','dlpfc','hpc']\n",
    "# coh_rois = ['acc','ains','ofc','dlpfc','vlpfc','amy']\n",
    "\n",
    "# dict of subj_ids with elecs in roi \n",
    "roi_subj_ids = {f'{roi}':roi_reref_labels_master_df.subj_id[\n",
    "    roi_reref_labels_master_df.roi == roi].unique().tolist() \n",
    "                for roi in coh_rois}\n",
    "# make unique list of pairs [[pair1,pair2],..] without hard coding \n",
    "pairs = [list(tup) for tup in list(itertools.combinations(coh_rois,2))]\n",
    "pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a23e9454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['dmpfc', 'amy'],\n",
       " ['dmpfc', 'ains'],\n",
       " ['dmpfc', 'ofc'],\n",
       " ['amy', 'ains'],\n",
       " ['amy', 'ofc'],\n",
       " ['ains', 'ofc'],\n",
       " ['acc', 'ofc'],\n",
       " ['acc', 'vlpfc'],\n",
       " ['acc', 'dlpfc'],\n",
       " ['acc', 'hpc'],\n",
       " ['ains', 'vlpfc'],\n",
       " ['ains', 'dlpfc'],\n",
       " ['ains', 'hpc'],\n",
       " ['dmpfc', 'vlpfc'],\n",
       " ['dmpfc', 'dlpfc'],\n",
       " ['dmpfc', 'hpc'],\n",
       " ['ofc', 'vlpfc'],\n",
       " ['ofc', 'dlpfc'],\n",
       " ['ofc', 'hpc'],\n",
       " ['amy', 'vlpfc'],\n",
       " ['amy', 'dlpfc'],\n",
       " ['amy', 'hpc'],\n",
       " ['vlpfc', 'dlpfc'],\n",
       " ['vlpfc', 'hpc'],\n",
       " ['dlpfc', 'hpc']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs = [\n",
    " ['dmpfc', 'amy'],\n",
    " ['dmpfc', 'ains'],\n",
    " ['dmpfc', 'ofc'],\n",
    " ['amy', 'ains'],\n",
    " ['amy', 'ofc'],\n",
    " ['ains', 'ofc'],\n",
    " ['acc', 'ofc'],\n",
    " ['acc', 'vlpfc'],\n",
    " ['acc', 'dlpfc'],\n",
    " ['acc', 'hpc'],\n",
    " ['ains', 'vlpfc'],\n",
    " ['ains', 'dlpfc'],\n",
    " ['ains', 'hpc'],\n",
    " ['dmpfc', 'vlpfc'],\n",
    " ['dmpfc', 'dlpfc'],\n",
    " ['dmpfc', 'hpc'],\n",
    " ['ofc', 'vlpfc'],\n",
    " ['ofc', 'dlpfc'],\n",
    " ['ofc', 'hpc'],\n",
    " ['amy', 'vlpfc'],\n",
    " ['amy', 'dlpfc'],\n",
    " ['amy', 'hpc'],\n",
    " ['vlpfc', 'dlpfc'],\n",
    " ['vlpfc', 'hpc'],\n",
    " ['dlpfc', 'hpc']]\n",
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d701981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /sc/arion/projects/guLab/Alie/SWB/ephys_analysis/data/MS011/MS011_MoodChoiceOnset_epochs.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -2000.00 ...    1000.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "50 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "   Processing epoch 50 / 50 ...\n",
      "   Processing epoch 49 / 50 ...\n",
      "   Processing epoch 3 / 50 ...\n",
      "   Processing epoch 6 / 50 ...\n",
      "   Processing epoch 6 / 50 ...\n",
      "   Processing epoch 5 / 50 ...\n",
      "   Processing epoch 7 / 50 ...\n",
      "   Processing epoch 7 / 50 ...\n",
      "   Processing epoch 7 / 50 ...\n",
      "   Processing epoch 10 / 50 ...\n",
      "   Processing epoch 11 / 50 ...\n",
      "   Processing epoch 11 / 50 ...\n"
     ]
    }
   ],
   "source": [
    "### resume coherence calculation with remaining pairs \n",
    "\n",
    "for pair in pairs:\n",
    "    \n",
    "    source_region = pair[0]\n",
    "    target_region = pair[1]    \n",
    "    \n",
    "    # unique pair id roi1_roi2\n",
    "    pair_id = '_'.join([source_region,target_region])\n",
    "    \n",
    "    # find subj with elecs in each roi \n",
    "    source_subj = roi_subj_ids[source_region]\n",
    "    target_subj = roi_subj_ids[target_region]\n",
    "    # find subj with elecs in both rois\n",
    "    pair_subj = list(set(source_subj).intersection(target_subj))    \n",
    "    # save pair subj list \n",
    "    \n",
    "    # initialize the storage list \n",
    "    all_subj_pair_df = []\n",
    "    \n",
    "    # iterate through pair subjects\n",
    "    for subj_id in pair_subj:\n",
    "        \n",
    "        # load & format rereferenced epoch data \n",
    "        subj_epochs = mne.read_epochs(f'{neural_dir}{subj_id}/{subj_id}_{epoch_id}_epochs.fif', preload=True)\n",
    "        subj_elecs  = subj_epochs.ch_names\n",
    "        \n",
    "        # construct the seed-to-target mapping based on subject's roi coverage \n",
    "        elec_roi_df = roi_reref_labels_master_df[roi_reref_labels_master_df.subj_id==subj_id].reset_index(drop=True)\n",
    "        # get ch names of subj elecs in roi \n",
    "        source_ch_names  = elec_roi_df.reref_ch_names[np.where(elec_roi_df.roi == source_region)[0]].tolist()\n",
    "        target_ch_names  = elec_roi_df.reref_ch_names[np.where(elec_roi_df.roi == target_region)[0]].tolist()\n",
    "        # get idx of ch in subj_elecs list (will correspond to idx in epochs array)\n",
    "        source_elec_idx = [subj_elecs.index(elec) for elec in source_ch_names]\n",
    "        target_elec_idx = [subj_elecs.index(elec) for elec in target_ch_names]\n",
    "        # make seed to target indices using mne function \n",
    "        seed_to_target = seed_target_indices(\n",
    "                        source_elec_idx,\n",
    "                        target_elec_idx)\n",
    "        \n",
    "        # elec name for every elec pair \n",
    "        subj_pair_ch = list(map(lambda x,y: '_'.join([x,y]), \n",
    "                                  [subj_elecs[idx] for idx in  seed_to_target[0]], \n",
    "                                  [subj_elecs[idx] for idx in  seed_to_target[1]]))\n",
    "        # unique elec name for every elec pair \n",
    "        unique_ch_pair = list(map(lambda x,y: '_'.join([x,y]), [subj_id]*len(subj_pair_ch), subj_pair_ch))\n",
    "        \n",
    "        # compute pwise coherence \n",
    "        pwise = oscillation_utils.compute_connectivity(subj_epochs, \n",
    "                                           band = freq_dict[band], \n",
    "                                           metric = metric, \n",
    "                                           indices = seed_to_target, \n",
    "                                           freqs = freqs, \n",
    "                                           n_cycles = n_cycles,\n",
    "                                           buf_ms = buf_ms, \n",
    "                                           n_surr=n_surr,\n",
    "                                           avg_over_dim='time',\n",
    "                                           band1 = freq_dict[band],\n",
    "                                           parallelize=True)\n",
    "\n",
    "        \n",
    "        coh_df = pd.concat([pd.DataFrame({'epoch':np.arange(0,pwise.shape[0]),'coh':pwise[:,ch_ix],\n",
    "                                          'unique_ch_pair':[ch_name]*pwise.shape[0],\n",
    "                                          'roi_pair_chans':['_'.join(ch_name.split('_')[1:])]*pwise.shape[0],\n",
    "                                          'roi1_ch_names':[ch_name.split('_')[1]]*pwise.shape[0],\n",
    "                                          'roi2_ch_names':[ch_name.split('_')[2]]*pwise.shape[0],\n",
    "                                          'roi1_elec_idx':[seed_to_target[0]]*pwise.shape[0],\n",
    "                                          'roi2_elec_idx':[seed_to_target[1]]*pwise.shape[0]}) \n",
    "                            for ch_ix, ch_name in enumerate(unique_ch_pair)])\n",
    "\n",
    "\n",
    "\n",
    "        coh_df['subj_id']  = subj_id\n",
    "        coh_df['bdi']      = all_mood[all_mood.subj_id == subj_id].bdi.unique().tolist()[0]\n",
    "        coh_df['Round']    = all_mood[all_mood.subj_id == subj_id].Round\n",
    "        coh_df['epoch']    = all_mood[all_mood.subj_id == subj_id].epoch\n",
    "        coh_df['band']     = band\n",
    "        coh_df['metric']   = metric\n",
    "        coh_df['pair_id']  = pair_id\n",
    "        coh_df['roi1']     = source_region\n",
    "        coh_df['roi2']     = target_region\n",
    "\n",
    "        # one pair one subj data \n",
    "        coh_df.to_csv(f'{save_subj_dir}{subj_id}_{pair_id}_{metric}_{band}_df.csv')\n",
    "        all_subj_pair_df.append(coh_df)\n",
    "        del coh_df, subj_epochs, pwise\n",
    "#         print(f'finished {subj_id} {pair_id}')\n",
    "        \n",
    "    # one pair all subj data \n",
    "#     print(f'finished all {pair_id}')\n",
    "    all_subj_pair_df = pd.concat(all_subj_pair_df).reset_index()\n",
    "    # save roi pair df separately \n",
    "    all_subj_pair_df.to_csv(f'{save_dir}{pair_id}_{metric}_{band}_df.csv', index=False)\n",
    "    \n",
    "    del all_subj_pair_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a246520d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finished_pairs = [file.split('_')[:2] for file in os.listdir(f'{save_dir}') if file.split('_')[-1] == 'df.csv' ]\n",
    "# finished_pairs\n",
    "\n",
    "\n",
    "# finished_subj = [file.split('_')[0] for file in os.listdir(f'{save_dir}single_subj/') if file.split('_')[1:3] == pair ]\n",
    "# finished_subj\n",
    "\n",
    "\n",
    "# pair_subj = [ subj_id for subj_id in pair_subj if subj_id not in finished_subj]\n",
    "# pair_subj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9a1ac8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## sanity check df includes all subj - when finishing pair in new session, df will only include recent subj\n",
    "\n",
    "# all_pair_subj = {}\n",
    "# df_pair_subj = {}\n",
    "\n",
    "# for pair in finished_pairs:\n",
    "    \n",
    "#     source_region = pair[0]\n",
    "#     target_region = pair[1]    \n",
    "    \n",
    "#     # unique pair id roi1_roi2\n",
    "#     pair_id = '_'.join([source_region,target_region])\n",
    "    \n",
    "#     # find subj with elecs in each roi \n",
    "#     source_subj = roi_subj_ids[source_region]\n",
    "#     target_subj = roi_subj_ids[target_region]\n",
    "#     # find subj with elecs in both rois\n",
    "#     pair_subj = list(set(source_subj).intersection(target_subj))    \n",
    "#     # save pair subj list \n",
    "#     all_pair_subj[pair_id] = pair_subj\n",
    "    \n",
    "#     pair_data = pd.read_csv(f'{save_dir}{pair_id}_{metric}_{band}_df_1sec.csv')\n",
    "#     df_pair_subj[pair_id] = pair_data.subj_id.unique().tolist()\n",
    "#     del pair_data\n",
    "\n",
    "\n",
    "# for pair in list(all_pair_subj.keys()):\n",
    "#     pair_subj = all_pair_subj[pair]\n",
    "#     df_subj = df_pair_subj[pair]\n",
    "#     if len(pair_subj)!=len(df_subj):\n",
    "#         print(pair)\n",
    "\n",
    "\n",
    "\n",
    "## remake pair data file with all pair subj included! \n",
    "\n",
    "# pair = ['acc','ains']\n",
    "\n",
    "# source_region = pair[0]\n",
    "# target_region = pair[1]    \n",
    "\n",
    "# # unique pair id roi1_roi2\n",
    "# pair_id = '_'.join([source_region,target_region])\n",
    "\n",
    "# # find subj with elecs in each roi \n",
    "# source_subj = roi_subj_ids[source_region]\n",
    "# target_subj = roi_subj_ids[target_region]\n",
    "# # find subj with elecs in both rois\n",
    "# pair_subj = list(set(source_subj).intersection(target_subj))    \n",
    "\n",
    "# pair_full_df = []\n",
    "\n",
    "# for subj_id in pair_subj:\n",
    "#     subj_pair_df = pd.read_csv(f'{save_dir}single_subj/{subj_id}_{source_region}_{target_region}_coh_{band}_df.csv')\n",
    "\n",
    "#     pair_full_df.append(subj_pair_df)\n",
    "#     del subj_pair_df\n",
    "    \n",
    "# pair_full_df = pd.concat(pair_full_df).reset_index(drop=True)\n",
    "\n",
    "# pair_full_df.to_csv(f'{save_dir}{pair_id}_{metric}_{band}_df_1sec.csv')\n",
    "\n",
    "# pair_full_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9a2c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## to compute coh after notebook ends in middle of roi pair\n",
    "# pairs = pairs[-4:]\n",
    "# pairs\n",
    "# pair_id = 'ofc_amy'\n",
    "# pair    = pairs[0]\n",
    "\n",
    "# source_region = pair[0]\n",
    "# target_region = pair[1]    \n",
    "\n",
    "# # unique pair id roi1_roi2\n",
    "# pair_id = '_'.join([source_region,target_region])\n",
    "\n",
    "# # find subj with elecs in each roi \n",
    "# source_subj = roi_subj_ids[source_region]\n",
    "# target_subj = roi_subj_ids[target_region]\n",
    "\n",
    "# # find subj with elecs in both rois\n",
    "# pair_subj = list(set(source_subj).intersection(target_subj))    \n",
    "# # find completed subj files\n",
    "# complete_subj_files = glob(f'{save_dir}*ofc_amy_coh_beta_df.csv')\n",
    "# complete_subj = [file.split('/')[-1].split('_')[0] for file in complete_subj_files]\n",
    "# # find subj from pair_subj with no saved data\n",
    "# incomplete_subj = list(np.setdiff1d(pair_subj, complete_subj)) # should be ['MS027','MS017']\n",
    "\n",
    "# # initialize the storage list \n",
    "# all_subj_pair_df = []\n",
    "\n",
    "# # run incomplete subj only! \n",
    "# for subj_id in incomplete_subj:\n",
    "\n",
    "#     # load & format rereferenced epoch data \n",
    "#     subj_epochs = mne.read_epochs(f'{neural_dir}{subj_id}/{epoch_id}_epochs-clean.fif', preload=True)\n",
    "#     subj_elecs  = subj_epochs.ch_names\n",
    "\n",
    "#     # construct the seed-to-target mapping based on subject's roi coverage \n",
    "#     elec_roi_df = roi_reref_labels_master_df[roi_reref_labels_master_df.subj_id==subj_id].reset_index(drop=True)\n",
    "#     # get ch names of subj elecs in roi \n",
    "#     source_ch_names  = elec_roi_df.reref_ch_names[np.where(elec_roi_df.roi == source_region)[0]].tolist()\n",
    "#     target_ch_names  = elec_roi_df.reref_ch_names[np.where(elec_roi_df.roi == target_region)[0]].tolist()\n",
    "#     # get idx of ch in subj_elecs list (will correspond to idx in epochs array)\n",
    "#     source_elec_idx = [subj_elecs.index(elec) for elec in source_ch_names]\n",
    "#     target_elec_idx = [subj_elecs.index(elec) for elec in target_ch_names]\n",
    "#     # make seed to target indices using mne function \n",
    "#     seed_to_target = seed_target_indices(\n",
    "#                     source_elec_idx,\n",
    "#                     target_elec_idx)\n",
    "\n",
    "#     # elec name for every elec pair \n",
    "#     subj_pair_ch = list(map(lambda x,y: '_'.join([x,y]), \n",
    "#                               [subj_elecs[idx] for idx in  seed_to_target[0]], \n",
    "#                               [subj_elecs[idx] for idx in  seed_to_target[1]]))\n",
    "#     # unique elec name for every elec pair \n",
    "#     unique_ch_pair = list(map(lambda x,y: '_'.join([x,y]), [subj_id]*len(subj_pair_ch), subj_pair_ch))\n",
    "\n",
    "#     # compute pwise coherence \n",
    "#     pwise = oscillation_utils.compute_connectivity(subj_epochs.copy(), \n",
    "#                                        band = freq_dict[band], \n",
    "#                                        metric = metric, \n",
    "#                                        indices = seed_to_target, \n",
    "#                                        freqs = freqs, \n",
    "#                                        n_cycles = n_cycles,\n",
    "#                                        buf_ms = buf_ms, \n",
    "#                                        n_surr=n_surr,\n",
    "#                                        avg_over_dim='time',\n",
    "#                                        band1 = freq_dict[band],\n",
    "#                                        parallelize=True)\n",
    "\n",
    "\n",
    "#     coh_df = pd.concat([pd.DataFrame({'epoch':np.arange(0,pwise.shape[0]),'coh':pwise[:,ch_ix],\n",
    "#                                       'unique_ch_pair':[ch_name]*pwise.shape[0],\n",
    "#                                       'roi_pair_chans':['_'.join(ch_name.split('_')[1:])]*pwise.shape[0],\n",
    "#                                       'roi1_ch_names':[ch_name.split('_')[1]]*pwise.shape[0],\n",
    "#                                       'roi2_ch_names':[ch_name.split('_')[2]]*pwise.shape[0],\n",
    "#                                       'roi1_elec_idx':[seed_to_target[0]]*pwise.shape[0],\n",
    "#                                       'roi2_elec_idx':[seed_to_target[1]]*pwise.shape[0]}) \n",
    "#                         for ch_ix, ch_name in enumerate(unique_ch_pair)])\n",
    "\n",
    "\n",
    "\n",
    "#     coh_df['subj_id']  = subj_id\n",
    "#     coh_df['bdi']      = all_behav[all_behav.subj_id == subj_id].bdi.unique().tolist()[0]\n",
    "#     coh_df['Round']    = all_behav[all_behav.subj_id == subj_id].Round\n",
    "#     coh_df['epoch']    = all_behav[all_behav.subj_id == subj_id].epoch\n",
    "#     coh_df['band']     = band\n",
    "#     coh_df['metric']   = metric\n",
    "#     coh_df['pair_id']  = pair_id\n",
    "#     coh_df['roi1']     = source_region\n",
    "#     coh_df['roi2']     = target_region\n",
    "\n",
    "#     # one pair one subj data \n",
    "#     coh_df.to_csv(f'{save_dir}{subj_id}_{pair_id}_{metric}_{band}_df.csv')\n",
    "#     all_subj_pair_df.append(coh_df)\n",
    "#     del coh_df, subj_epochs,pwise\n",
    "\n",
    "# # add completed subj dfs to concat list \n",
    "# for file in complete_subj_files:\n",
    "#     subj_id = file.split('/')[-1].split('_')[0]\n",
    "#     coh_df = pd.read_csv(file)\n",
    "#     all_subj_pair_df.append(coh_df)\n",
    "\n",
    "# # make pair df \n",
    "# all_subj_pair_df = pd.concat(all_subj_pair_df).reset_index()\n",
    "# # save roi pair df  \n",
    "# all_subj_pair_df.to_csv(f'{save_dir}{pair_id}_{metric}_{band}_df.csv', index=False)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670a5689",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swb_lfp",
   "language": "python",
   "name": "swb_lfp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
