{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c2d4a3d9",
   "metadata": {},
   "source": [
    "# CPC 2023 SWB Ephys Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "137d21e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e67d258",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import mne\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import seaborn as sns\n",
    "from scipy.stats import zscore, linregress, ttest_ind, ttest_rel, ttest_1samp\n",
    "import pandas as pd\n",
    "from mne.preprocessing.bads import _find_outliers\n",
    "import os \n",
    "import joblib\n",
    "import emd\n",
    "import re\n",
    "import scipy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c869ba08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/alexandrafink/Documents/GraduateSchool/SaezLab/SWB/ephys_analysis/scripts/saez_python_pipeline/LFPAnalysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "397f24df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from LFPAnalysis import lfp_preprocess_utils, sync_utils, analysis_utils, nlx_utils"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c75a2d95",
   "metadata": {},
   "source": [
    "## Load epoched data and subj info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32eeae73",
   "metadata": {},
   "outputs": [],
   "source": [
    "swb_dir = '/Users/alexandrafink/Documents/GraduateSchool/SaezLab/SWB/'\n",
    "anat_dir = f'{swb_dir}anat_recons/recon_labels/'\n",
    "neural_dir = f'{swb_dir}ephys_analysis/data/'\n",
    "behav_dir = f'{swb_dir}behavior_analysis/behavior_preprocessed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ce230d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_list = pd.read_excel(f'{swb_dir}presentations/cpc_2023_poster/subjects.xlsx', sheet_name='patient_info', usecols=[0])\n",
    "subj_ids = list(subj_list.PatientID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a8fff4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionaries for data storage\n",
    "elec_dict = {f'{x}': [] for x in subj_ids}\n",
    "behav_dict = {f'{x}': [] for x in subj_ids}\n",
    "evs = {'DecisionOnset': [0, 3.0],\n",
    "       'TrialOnset': [-1.0, 0]}\n",
    "epochs_all_subjs_all_evs = {f'{a}': {f'{b}': np.nan for b in evs.keys()} for a in subj_ids}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5fa08a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load epoched data\n",
    "for subj_id in subj_ids:\n",
    "    ## Load the electrode localization data & save to group dict\n",
    "    anat_file = glob(f'{anat_dir}{subj_id}_labels.csv')[0]\n",
    "    elec_locs = pd.read_csv(anat_file)\n",
    "    elec_locs = elec_locs[elec_locs.columns.drop(list(elec_locs.filter(regex='Unnamed')))]\n",
    "    elec_dict[subj_id] = elec_locs\n",
    "    ## Load behavioral data & save to group dict\n",
    "    behav_df = pd.read_csv(f'{behav_dir}{subj_id}_pt_task_data')\n",
    "    behav_df = behav_df[behav_df.columns.drop(list(behav_df.filter(regex='Unnamed')))]\n",
    "    behav_dict[subj_id] = behav_df\n",
    "\n",
    "    for event in evs.keys():\n",
    "        \n",
    "        ev_epochs = mne.read_epochs(f'{neural_dir}{subj_id}/epoch_{event}.fif', preload=True)\n",
    "        \n",
    "        epochs_all_subjs_all_evs[subj_id][event] = ev_epochs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ad420dd6",
   "metadata": {},
   "source": [
    "## Wavelet TFRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b7a04b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_evs = ['DecisionOnset']\n",
    "baseline_ev = 'TrialOnset'\n",
    "evs = {'DecisionOnset': [0, 3.0],\n",
    "       'TrialOnset': [-1.0, 0]}\n",
    "\n",
    "for i in analysis_evs: \n",
    "    if i not in evs.keys(): \n",
    "        raise ValueError('This analysis event is not in the dictionary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f78510ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some spectrogram parameters \n",
    "freqs = np.logspace(*np.log10([4, 200]), num=30)\n",
    "n_cycles = 4  \n",
    "sr = 500\n",
    "buf = 1.0\n",
    "buf_ix = int(buf*sr)\n",
    "\n",
    "\n",
    "baseline_power_epochs = {f'{a}': {f'{b}': np.nan for b in evs.keys()} for a in subj_ids}\n",
    "\n",
    "power_epochs = {f'{a}': {f'{b}': np.nan for b in evs.keys()} for a in subj_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "339b17b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute baseline_power\n",
    "for subj_id in subj_ids:\n",
    "    event = 'TrialOnset'\n",
    "    epochs = epochs_all_subjs_all_evs[subj_id][event]\n",
    "        \n",
    "    # Let's make sure we only do this for good channels\n",
    "    good_chans = [x for x in epochs.ch_names if x not in epochs.info['bads']]\n",
    "    picks = [x for x in good_chans]\n",
    "\n",
    "    pow_struct = np.nan * np.ones([epochs._data.shape[0], \n",
    "                           epochs._data.shape[1], len(freqs), \n",
    "                           epochs._data.shape[-1]])\n",
    "\n",
    "    for ch_ix in np.arange(epochs._data.shape[1]): \n",
    "        ch_data = epochs._data[:, ch_ix:ch_ix+1, :]\n",
    "        bad_epochs  = np.where(epochs.metadata[epochs.ch_names[ch_ix]].notnull())[0]\n",
    "        good_epochs = np.delete(np.arange(ch_data.shape[0]), bad_epochs)\n",
    "        ch_data = np.delete(ch_data, bad_epochs, axis=0)\n",
    "        ch_pow = mne.time_frequency.tfr_array_morlet(ch_data, sfreq=epochs.info['sfreq'], \n",
    "                                            freqs=freqs, n_cycles=n_cycles, zero_mean=False, \n",
    "                                            use_fft=True, output='power', n_jobs=1)\n",
    "\n",
    "        pow_struct[good_epochs, ch_ix, :, :] = ch_pow[:, 0, :, :]\n",
    "\n",
    "    temp_pow = mne.time_frequency.EpochsTFR(epochs.info, pow_struct, \n",
    "                                            epochs.times, freqs)\n",
    "    temp_pow.crop(tmin=evs[event][0], tmax=evs[event][1])\n",
    "\n",
    "    baseline_power_epochs[subj_id][event] = temp_pow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac351929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DA8': {'DecisionOnset': nan,\n",
       "  'TrialOnset': <EpochsTFR | time : [-1.000000, 0.000000], freq : [4.000000, 200.000000], epochs : 150, channels : 57, ~1004.0 MB>},\n",
       " 'DA9': {'DecisionOnset': nan,\n",
       "  'TrialOnset': <EpochsTFR | time : [-1.000000, 0.000000], freq : [4.000000, 200.000000], epochs : 150, channels : 44, ~756.9 MB>},\n",
       " 'DA10': {'DecisionOnset': nan,\n",
       "  'TrialOnset': <EpochsTFR | time : [-1.000000, 0.000000], freq : [4.000000, 200.000000], epochs : 150, channels : 41, ~705.3 MB>},\n",
       " 'DA11': {'DecisionOnset': nan,\n",
       "  'TrialOnset': <EpochsTFR | time : [-1.000000, 0.000000], freq : [4.000000, 200.000000], epochs : 151, channels : 91, ~1.54 GB>},\n",
       " 'DA023': {'DecisionOnset': nan,\n",
       "  'TrialOnset': <EpochsTFR | time : [-1.000000, 0.000000], freq : [4.000000, 200.000000], epochs : 150, channels : 125, ~2.15 GB>},\n",
       " 'MS002': {'DecisionOnset': nan,\n",
       "  'TrialOnset': <EpochsTFR | time : [-1.000000, 0.000000], freq : [4.000000, 200.000000], epochs : 150, channels : 125, ~2.15 GB>},\n",
       " 'MS003': {'DecisionOnset': nan,\n",
       "  'TrialOnset': <EpochsTFR | time : [-1.000000, 0.000000], freq : [4.000000, 200.000000], epochs : 150, channels : 110, ~1.89 GB>},\n",
       " 'MS016': {'DecisionOnset': nan,\n",
       "  'TrialOnset': <EpochsTFR | time : [-1.000000, 0.000000], freq : [4.000000, 200.000000], epochs : 150, channels : 129, ~2.22 GB>},\n",
       " 'MS017': {'DecisionOnset': nan,\n",
       "  'TrialOnset': <EpochsTFR | time : [-1.000000, 0.000000], freq : [4.000000, 200.000000], epochs : 150, channels : 86, ~1.48 GB>},\n",
       " 'MS019': {'DecisionOnset': nan,\n",
       "  'TrialOnset': <EpochsTFR | time : [-1.000000, 0.000000], freq : [4.000000, 200.000000], epochs : 150, channels : 138, ~2.37 GB>},\n",
       " 'MS022': {'DecisionOnset': nan,\n",
       "  'TrialOnset': <EpochsTFR | time : [-1.000000, 0.000000], freq : [4.000000, 200.000000], epochs : 150, channels : 56, ~986.4 MB>},\n",
       " 'MS025': {'DecisionOnset': nan,\n",
       "  'TrialOnset': <EpochsTFR | time : [-1.000000, 0.000000], freq : [4.000000, 200.000000], epochs : 150, channels : 131, ~2.20 GB>},\n",
       " 'MS026': {'DecisionOnset': nan,\n",
       "  'TrialOnset': <EpochsTFR | time : [-1.000000, 0.000000], freq : [4.000000, 200.000000], epochs : 150, channels : 135, ~2.27 GB>},\n",
       " 'MS027': {'DecisionOnset': nan,\n",
       "  'TrialOnset': <EpochsTFR | time : [-1.000000, 0.000000], freq : [4.000000, 200.000000], epochs : 150, channels : 114, ~1.96 GB>},\n",
       " 'MS029': {'DecisionOnset': nan,\n",
       "  'TrialOnset': <EpochsTFR | time : [-1.000000, 0.000000], freq : [4.000000, 200.000000], epochs : 150, channels : 114, ~1.96 GB>},\n",
       " 'MS030': {'DecisionOnset': nan,\n",
       "  'TrialOnset': <EpochsTFR | time : [-1.000000, 0.000000], freq : [4.000000, 200.000000], epochs : 150, channels : 99, ~1.70 GB>}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_power_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e38bea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pickle module\n",
    "import pickle\n",
    "\n",
    "save_path = f'{swb_dir}presentations/cpc_2023_poster/data/'\n",
    "\n",
    "# create a binary pickle file \n",
    "f = open(f'{save_path}/epochs_07032023.pkl',\"wb\")\n",
    "\n",
    "# write the python object (dict) to pickle file\n",
    "pickle.dump(epochs_all_subjs_all_evs,f)\n",
    "\n",
    "# close file\n",
    "f.close()\n",
    "\n",
    "# create a binary pickle file \n",
    "f = open(f'{save_path}/baseline_epochs_07032023.pkl',\"wb\")\n",
    "\n",
    "# write the python object (dict) to pickle file\n",
    "pickle.dump(baseline_power_epochs,f)\n",
    "\n",
    "# close file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1010ff08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "save_path = f'{swb_dir}presentations/cpc_2023_poster/data/'\n",
    "\n",
    "epochs_all_subjs_all_evs = pd.read_pickle(rf'{save_path}epochs_07032023.pkl')\n",
    "baseline_power_epochs = pd.read_pickle(rf'{save_path}baseline_epochs_07032023.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e2ca5e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DA8',\n",
       " 'DA9',\n",
       " 'DA10',\n",
       " 'DA11',\n",
       " 'DA023',\n",
       " 'MS002',\n",
       " 'MS003',\n",
       " 'MS016',\n",
       " 'MS017',\n",
       " 'MS019',\n",
       " 'MS022',\n",
       " 'MS025',\n",
       " 'MS026',\n",
       " 'MS027',\n",
       " 'MS029',\n",
       " 'MS030']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subj_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c210d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "power_epochs = {f'{a}': {f'{b}': np.nan for b in evs.keys()} for a in subj_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c6b8cc11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS030\n"
     ]
    }
   ],
   "source": [
    "subj_id = 'MS030'\n",
    "print(subj_id)\n",
    "event = 'DecisionOnset'        \n",
    "epochs = epochs_all_subjs_all_evs[subj_id][event]\n",
    "            \n",
    "# Let's make sure we only do this for good channels\n",
    "good_chans = [x for x in epochs.ch_names if x not in epochs.info['bads']]\n",
    "picks = [x for x in good_chans]\n",
    "\n",
    "pow_struct = np.nan * np.ones([epochs._data.shape[0], \n",
    "                        epochs._data.shape[1], len(freqs), \n",
    "                        epochs._data.shape[-1]])\n",
    "\n",
    "for ch_ix in np.arange(epochs._data.shape[1]): \n",
    "    ch_data = epochs._data[:, ch_ix:ch_ix+1, :]\n",
    "    bad_epochs  = np.where(epochs.metadata[epochs.ch_names[ch_ix]].notnull())[0]\n",
    "    good_epochs = np.delete(np.arange(ch_data.shape[0]), bad_epochs)\n",
    "    ch_data = np.delete(ch_data, bad_epochs, axis=0)\n",
    "    ch_pow = mne.time_frequency.tfr_array_morlet(ch_data, sfreq=epochs.info['sfreq'], \n",
    "                                        freqs=freqs, n_cycles=n_cycles, zero_mean=False, \n",
    "                                        use_fft=True, output='power', n_jobs=1)\n",
    "\n",
    "    pow_struct[good_epochs, ch_ix, :, :] = ch_pow[:, 0, :, :]\n",
    "\n",
    "temp_pow = mne.time_frequency.EpochsTFR(epochs.info, pow_struct, \n",
    "                                        epochs.times, freqs)\n",
    "\n",
    "temp_pow.crop(tmin=evs[event][0], tmax=evs[event][1])\n",
    "\n",
    "baseline_corrected_power = lfp_preprocess_utils.zscore_TFR_across_trials(temp_pow.data, \n",
    "                                baseline_power_epochs[subj_id]['TrialOnset'], mode='zscore', baseline_only=False)\n",
    "\n",
    "zpow = mne.time_frequency.EpochsTFR(epochs.info, baseline_corrected_power, \n",
    "                                temp_pow.times, freqs)\n",
    "\n",
    "zpow.metadata = epochs_all_subjs_all_evs[subj_id][event].metadata\n",
    "\n",
    "power_epochs[subj_id][event] = zpow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f1225f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pickle module\n",
    "import pickle\n",
    "\n",
    "save_path = f'{swb_dir}presentations/cpc_2023_poster/data/'\n",
    "\n",
    "# create a binary pickle file \n",
    "# f = open(f'{save_path}power_epochs_davis.pkl',\"wb\")\n",
    "# f = open(f'{save_path}power_epochs_ms2toms16.pkl',\"wb\")\n",
    "# f = open(f'{save_path}power_epochs_ms17toms22.pkl',\"wb\")\n",
    "# f = open(f'{save_path}power_epochs_ms25toms27.pkl',\"wb\")\n",
    "# f = open(f'{save_path}power_epochs_ms29toms30.pkl',\"wb\")\n",
    "# f = open(f'{save_path}power_epochs_ms29.pkl',\"wb\") #had to redo - behavioral metadata didn't save originally\n",
    "f = open(f'{save_path}power_epochs_ms30.pkl',\"wb\") #reran separately to save data\n",
    "\n",
    "# write the python object (dict) to pickle file\n",
    "pickle.dump(power_epochs,f)\n",
    "\n",
    "# close file\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7161c59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "del power_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "def61aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "del epochs_all_subjs_all_evs\n",
    "del baseline_power_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3ab7334",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# #baseline correct analysis ev \n",
    "# for subj_id in subj_ids:\n",
    "#     event = 'DecisionOnset'\n",
    "            \n",
    "#     epochs = epochs_all_subjs_all_evs[subj_id][event]\n",
    "        \n",
    "#     # Let's make sure we only do this for good channels\n",
    "#     good_chans = [x for x in epochs.ch_names if x not in epochs.info['bads']]\n",
    "#     picks = [x for x in good_chans]\n",
    "    \n",
    "#     pow_struct = np.nan * np.ones([epochs._data.shape[0], \n",
    "#                             epochs._data.shape[1], len(freqs), \n",
    "#                             epochs._data.shape[-1]])\n",
    "\n",
    "#     for ch_ix in np.arange(epochs._data.shape[1]): \n",
    "#         ch_data = epochs._data[:, ch_ix:ch_ix+1, :]\n",
    "#         bad_epochs  = np.where(epochs.metadata[epochs.ch_names[ch_ix]].notnull())[0]\n",
    "#         good_epochs = np.delete(np.arange(ch_data.shape[0]), bad_epochs)\n",
    "#         ch_data = np.delete(ch_data, bad_epochs, axis=0)\n",
    "#         ch_pow = mne.time_frequency.tfr_array_morlet(ch_data, sfreq=epochs.info['sfreq'], \n",
    "#                                             freqs=freqs, n_cycles=n_cycles, zero_mean=False, \n",
    "#                                             use_fft=True, output='power', n_jobs=1)\n",
    "\n",
    "#         pow_struct[good_epochs, ch_ix, :, :] = ch_pow[:, 0, :, :]\n",
    "    \n",
    "#     temp_pow = mne.time_frequency.EpochsTFR(epochs.info, pow_struct, \n",
    "#                                             epochs.times, freqs)\n",
    "    \n",
    "#     temp_pow.crop(tmin=evs[event][0], tmax=evs[event][1])\n",
    "    \n",
    "#     baseline_corrected_power = lfp_preprocess_utils.zscore_TFR_across_trials(temp_pow.data, \n",
    "#                                     baseline_power_epochs[subj_id]['TrialOnset'], mode='zscore', baseline_only=False)\n",
    "    \n",
    "#     zpow = mne.time_frequency.EpochsTFR(epochs.info, baseline_corrected_power, \n",
    "#                                     temp_pow.times, freqs)\n",
    "    \n",
    "#     zpow.metadata = epochs_all_subjs_all_evs[subj_id][event].metadata\n",
    "    \n",
    "#     power_epochs[subj_id][event] = zpow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a6033829",
   "metadata": {},
   "source": [
    "# TFR Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4878085e",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path = f'{swb_dir}presentations/cpc_2023_poster/data/'\n",
    "power_epochs_davis = pd.read_pickle(f'{load_path}power_epochs_davis.pkl')\n",
    "power_epochs_ms2toms16 = pd.read_pickle(f'{load_path}power_epochs_ms2toms16.pkl')\n",
    "power_epochs_ms17toms22 = pd.read_pickle(f'{load_path}power_epochs_ms17toms22.pkl')\n",
    "power_epochs_ms25toms27 = pd.read_pickle(f'{load_path}power_epochs_ms25toms27.pkl')\n",
    "power_epochs_ms29toms30 = pd.read_pickle(f'{load_path}power_epochs_ms29toms30.pkl')\n",
    "power_epochs_ms29toms30 = pd.read_pickle(f'{load_path}power_epochs_ms29.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b615eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "power_epochs = {f'{a}': {f'{b}': np.nan for b in evs.keys()} for a in subj_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3239481",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load epoched data\n",
    "for subj_id in subj_ids:\n",
    "    ## Load the electrode localization data & save to group dict\n",
    "    anat_file = glob(f'{anat_dir}{subj_id}_labels.csv')[0]\n",
    "    elec_locs = pd.read_csv(anat_file)\n",
    "    elec_locs = elec_locs[elec_locs.columns.drop(list(elec_locs.filter(regex='Unnamed')))]\n",
    "    elec_dict[subj_id] = elec_locs\n",
    "    ## Load behavioral data & save to group dict\n",
    "    behav_df = pd.read_csv(f'{behav_dir}{subj_id}_pt_task_data')\n",
    "    behav_df = behav_df[behav_df.columns.drop(list(behav_df.filter(regex='Unnamed')))]\n",
    "    behav_dict[subj_id] = behav_df\n",
    "\n",
    "    for event in evs.keys():\n",
    "        \n",
    "        ev_epochs = mne.read_epochs(f'{neural_dir}{subj_id}/epoch_{event}.fif', preload=True)\n",
    "        \n",
    "        epochs_all_subjs_all_evs[subj_id][event] = ev_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3de4af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rois = ['vmPFC','Superior frontal', 'Middle frontal','Inferior frontal','Orbital frontal','Cingulate','Insula','Amygdala','Hippocampus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cd502e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionaries for data storage\n",
    "elec_dict = {f'{x}': [] for x in subj_ids}\n",
    "behav_dict = {f'{x}': [] for x in subj_ids}\n",
    "evs = {'DecisionOnset': [0, 3.0],\n",
    "       'TrialOnset': [-1.0, 0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639fcab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfrs\n",
    "event = 'DecisionOnset'\n",
    "\n",
    "# rois = ['hippocampus', 'amygdala', 'insular', 'cingulate' ,'orbital']\n",
    "region = 'orbital'\n",
    "\n",
    "# band definitions for y-axis\n",
    "yticks = [4, 8, 13, 30, 60, 120]\n",
    "\n",
    "# task condition to contrast \n",
    "#conditions = [\"(outcome=='good')\",\n",
    " #            \"(outcome=='bad')\"]\n",
    "\n",
    "#cond_name = 'outcome'\n",
    "\n",
    "# task condition to contrast \n",
    "conditions = [\"(regret<0)\",\n",
    "              \"(regret==0)\"]\n",
    "\n",
    "\n",
    "cond_name = 'regret'\n",
    "\n",
    "for subj_id in subj_ids:\n",
    "    # Get electrode df \n",
    "    elec_file = anat_path + subj_id + '_labels.csv'\n",
    "\n",
    "    elec_data = lfp_preprocess_utils.load_elec(elec_file)\n",
    "\n",
    "    anode_list = [x.split('-')[0] for x in epochs_all_subjs_all_evs[subj_id][event].ch_names]\n",
    "    elec_df = elec_data[elec_data.label.str.lower().isin(anode_list)]\n",
    "    elec_df['label'] = epochs_all_subjs_all_evs[subj_id][event].ch_names\n",
    "    elec_data = elec_data.dropna(how='all')\n",
    "\n",
    "    picks = analysis_utils.select_picks_rois(elec_df, region)\n",
    "    \n",
    "    for event in analysis_evs:\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(20, 6), dpi=300)\n",
    "        for ix, cond in enumerate(conditions):\n",
    "            # Set the times for \n",
    "            times = power_epochs[subj_id][event].times\n",
    "            plot_data = np.nanmean(np.nanmean(power_epochs[subj_id][event][cond].copy().pick_channels(picks).data, axis=0), axis=0)\n",
    "\n",
    "            im = ax[ix].imshow(plot_data,\n",
    "                      extent=[times[0], times[-1], freqs[0], freqs[-1]], interpolation='Bicubic',\n",
    "                      aspect='auto', origin='lower', cmap='RdBu_r', vmin = -np.nanmax(np.abs(plot_data)), vmax = np.nanmax(np.abs(plot_data)))\n",
    "            ax[ix].set(yticks=yticks, xlabel='Time (s)', ylabel='Frequency', title=f'{subj_id}_{region}_{cond}_{event}')\n",
    "            fig.colorbar(im, ax=ax[ix])\n",
    "        #plt.savefig('/Users/alexandrafink/Documents/GraduateSchool/Classes/ML/final_proj/data/figs/decision5sec/'+subj_id+'_'+region+'_'+cond_name+'.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93356098",
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute within trial mean for regression data\n",
    "# data is n_epochs, n_elecs, n_freq, time\n",
    "\n",
    "\n",
    "all_subj_epochs = []\n",
    "\n",
    "event = 'DecisionOnset'\n",
    "cond = 'regret'\n",
    "freq_bands = np.logspace(*np.log10([4, 120]), num=20)\n",
    "\n",
    "\n",
    "for ix, subj_id in enumerate(subj_ids):\n",
    "    data = power_epochs[subj_id]['DecisionOnset'].to_data_frame()\n",
    "    subj_num = ix \n",
    "    ch_names = power_epochs[subj_id]['DecisionOnset'].ch_names\n",
    "    elec_names = [x.split('-')[0] for x in ch_names]\n",
    "    for ch in ch_names:\n",
    "        elec_name = ch.split('-')[0]\n",
    "        for f in freq_bands:\n",
    "            #freq_band = data.freqs[freq] #value of frequency\n",
    "            for epoch in range(150):\n",
    "                #idx = (subj_num+1)*epoch*(freq+1)\n",
    "                y = power_epochs[subj_id]['DecisionOnset'].metadata.regret[epoch]\n",
    "                all_subj_epochs.append({\n",
    "                    'subj':subj_num,\n",
    "                    'epoch':epoch,\n",
    "                    'freq':f,\n",
    "                    'elec':elec_name,\n",
    "                    'av_pow': np.nanmean(data[ch][(data['freq'] == f) & (data['epoch']==epoch)],axis=0),\n",
    "                    'regret':y_lab\n",
    "                })\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea0cdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_df = pd.DataFrame(all_subj_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:LFPAnalysis]",
   "language": "python",
   "name": "conda-env-LFPAnalysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
